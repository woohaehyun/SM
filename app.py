
import streamlit as st
import pandas as pd
import io
import zipfile
import os
import re
from datetime import timedelta

st.set_page_config(page_title="ì‹ ëª…ì•½í’ˆ ìë™ë°œì£¼", layout="wide")

# ============= ì‚¬ì´ë“œë°” / í—¤ë” =============
st.sidebar.header("ğŸ“‚ íŒŒì¼ ì—…ë¡œë“œ")
sales_file = st.sidebar.file_uploader("ë§¤ì¶œìë£Œ ì—…ë¡œë“œ", type=["xlsx"])
purchase_file = st.sidebar.file_uploader("ë§¤ì…ìë£Œ ì—…ë¡œë“œ", type=["xlsx"])
stock_file = st.sidebar.file_uploader("í˜„ì¬ê³  ì—…ë¡œë“œ", type=["xlsx"])
logo_upload = st.sidebar.file_uploader("ë¡œê³  ì´ë¯¸ì§€(ì„ íƒ)", type=["png","jpg","jpeg","webp"])
name_map_file = st.sidebar.file_uploader("ëª…ì¹­ ë§¤í•‘í‘œ(ì„ íƒ: from,to)", type=["xlsx","csv"])

st.sidebar.divider()
# ë°œì£¼ì„œ ì–‘ì‹ ì˜µì…˜: ë§¤ì…ì²˜ ì œì™¸(ì œì¡°ì‚¬ ê¸°ì¤€)
manufacturer_only = st.sidebar.checkbox("ë°œì£¼ì„œ ì–‘ì‹: ë§¤ì…ì²˜ ì œì™¸(ì œì¡°ì‚¬ ê¸°ì¤€)", value=True)

# (ê³ ê¸‰) ë‚´ë¶€ í‘œì‹œëŠ” ììœ ë¡­ê²Œ ë³´ë˜, ì‹¤ì œ ë‚´ë³´ë‚´ê¸°ëŠ” ì œì¡°ì‚¬ ê¸°ì¤€ìœ¼ë¡œ ê°•ì œ
group_mode = st.sidebar.radio("ğŸ“ í™”ë©´ ê·¸ë£¹ ê¸°ì¤€(ë¯¸ë¦¬ë³´ê¸°ìš©)", ["ì œì¡°ì‚¬", "ë§¤ì…ì²˜", "ì œì¡°ì‚¬+ë§¤ì…ì²˜"], index=0, help="ì‹¤ì œ ë°œì£¼ì„œ íŒŒì¼ì€ ìœ„ ì²´í¬ê°€ ì¼œì ¸ ìˆìœ¼ë©´ ì œì¡°ì‚¬ ê¸°ì¤€ìœ¼ë¡œë§Œ ë§Œë“¤ì–´ì§‘ë‹ˆë‹¤.")

st.sidebar.divider()
mode = st.sidebar.radio("ğŸ“… ë¶„ì„ ê¸°ê°„", ["ìë™ (ìµœê·¼ 3ê°œì›”)", "ìˆ˜ë™ ì§€ì •"])

st.sidebar.divider()
use_recent_purchase = st.sidebar.checkbox("ìµœê·¼ ì…ê³ ìˆ˜ëŸ‰ ë°˜ì˜í•˜ì—¬ ê³¼ë°œì£¼ ë°©ì§€", value=True)
recent_days = st.sidebar.number_input("ìµœê·¼ ì…ê³  ë°˜ì˜ ì¼ìˆ˜", min_value=1, max_value=90, value=14, step=1)

st.sidebar.divider()
days_options = list(range(1, 366))
days_label_map = {d: f"{d}ì¼" for d in days_options}
selected_days = st.sidebar.selectbox("ë°œì£¼ ê¸°ì¤€(ìµœê·¼ Nì¼ íŒë§¤ëŸ‰)", options=days_options, format_func=lambda x: days_label_map[x], index=29)  # ê¸°ë³¸ 30ì¼

min_shortage = st.sidebar.number_input("ë¶€ì¡±ìˆ˜ëŸ‰ í•˜í•œ(ì´ìƒë§Œ í‘œì‹œ)", min_value=0, value=0, step=1)
show_only_to_order = st.sidebar.checkbox("ë°œì£¼ í•„ìš” í•­ëª©ë§Œ ë³´ê¸°(ë¶€ì¡±ìˆ˜ëŸ‰>0)", value=True)

st.sidebar.divider()
export_mode = st.sidebar.radio("ì—‘ì…€ ë‚´ë³´ë‚´ê¸° ë°©ì‹", ["ê·¸ë£¹ë³„ ê°œë³„ íŒŒì¼ (ZIP)", "í•œ íŒŒì¼(íƒ­ êµ¬ë¶„)"], index=1)

# ===== í—¤ë” ì˜ì—­ =====
c1, c2 = st.columns([1, 5])
with c1:
    try:
        if logo_upload is not None:
            st.image(logo_upload, width=100)
        elif os.path.exists("ë¡œê³ ë¦¬ë‰´ì–¼.png"):
            st.image("ë¡œê³ ë¦¬ë‰´ì–¼.png", width=230)
        else:
            st.empty()
    except Exception:
        st.empty()
with c2:
    st.title("ğŸ’Š ì‹ ëª…ì•½í’ˆ ìë™ë°œì£¼ì•±")
   
# ======== ìœ í‹¸ ========
def normalize_columns(df, mapping):
    df = df.copy()
    df.rename(columns={k: v for k, v in mapping.items() if k in df.columns}, inplace=True)
    return df

def require_columns(df, required, name):
    missing = [c for c in required if c not in df.columns]
    if missing:
        st.error(f"{name}ì— í•„ìš”í•œ ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤: {', '.join(missing)}")
        st.stop()

def to_upper_strip(series):
    return series.astype(str).str.strip().str.upper()

def clean_party_name(series):
    rep = [("ãˆœ",""),("(ì£¼)",""),("ì£¼ì‹íšŒì‚¬",""),("(ìœ )",""),("ìœ í•œíšŒì‚¬",""),("(ì¬)",""),("ì¬ë‹¨ë²•ì¸",""),("(ì‚¬)",""),("ì‚¬ë‹¨ë²•ì¸","")]
    s = series.astype(str).str.upper()
    for a,b in rep:
        s = s.str.replace(a, b, regex=False)
    s = s.str.replace(r"\s+", " ", regex=True).str.strip()
    return s

def apply_name_mapping(series, mapping_df):
    if mapping_df is None:
        return series
    m = mapping_df.copy()
    m.columns = [c.strip().lower() for c in m.columns]
    if not set(["from","to"]).issubset(set(m.columns)):
        return series
    s_clean = series.astype(str).str.upper().str.strip()
    m["from"] = m["from"].astype(str).str.upper().str.strip()
    m["to"] = m["to"].astype(str).str.strip()
    return s_clean.map(dict(zip(m["from"], m["to"]))).fillna(series)

def sanitize_sheet_name(name: str) -> str:
    if name is None or str(name).strip() == "":
        return "ë¯¸ì§€ì •"
    s = str(name)
    s = re.sub(r"[\[\]\*\?/\\:]", "-", s)
    return s[:31]

def write_formatted_sheet(writer, sheet_name, df):
    df = df.copy()
    df.to_excel(writer, index=False, sheet_name=sheet_name)
    workbook  = writer.book
    ws = writer.sheets[sheet_name]

    header_fmt = workbook.add_format({"bold": True, "bg_color": "#F2F4F7", "border": 1, "align": "center", "valign": "vcenter"})
    num_fmt    = workbook.add_format({"num_format": "#,##0"})
    strong_fmt = workbook.add_format({"bg_color": "#FFE5E5", "bold": True})
    over_fmt   = workbook.add_format({"bg_color": "#EAF4FF"})
    base_fmt   = workbook.add_format({"text_wrap": False})

    # í—¤ë” ì„œì‹
    for col_idx, col in enumerate(df.columns):
        ws.write(0, col_idx, col, header_fmt)

    # ì—´ ë„ˆë¹„ ìë™
    for i, col in enumerate(df.columns):
        try:
            maxlen = max(df[col].astype(str).map(len).max(), len(col))
        except Exception:
            maxlen = len(col)
        ws.set_column(i, i, min(maxlen + 2, 40), num_fmt if pd.api.types.is_numeric_dtype(df[col]) else base_fmt)

    ws.set_default_row(20)
    ws.set_row(0, 24)
    ws.freeze_panes(1, 0)
    ws.autofilter(0, 0, len(df), len(df.columns)-1)

    # ì¡°ê±´ë¶€ì„œì‹
    col_map = {c:i for i,c in enumerate(df.columns)}
    last_row = len(df)
    if "ë¶€ì¡±ìˆ˜ëŸ‰" in col_map:
        i = col_map["ë¶€ì¡±ìˆ˜ëŸ‰"]
        ws.conditional_format(1, i, last_row, i, {"type":"cell","criteria":">","value":0,"format":strong_fmt})
    if "ë°œì£¼ìˆ˜ëŸ‰" in col_map:
        i = col_map["ë°œì£¼ìˆ˜ëŸ‰"]
        ws.conditional_format(1, i, last_row, i, {"type":"cell","criteria":">","value":0,"format":strong_fmt})
    if "ê³¼ì¬ê³ " in col_map:
        i = col_map["ê³¼ì¬ê³ "]
        ws.conditional_format(1, i, last_row, i, {"type":"cell","criteria":">","value":0,"format":over_fmt})

# ==== ë°ì´í„° ê²€ì¦ ë¦¬í¬íŠ¸(ê°„ë‹¨ ìš”ì•½) ====
def validate_and_report(sales_raw, purchase_raw, stock_raw):
    req_sales = ["ëª…ì„¸ì¼ì", "ìƒ í’ˆ ëª…", "í¬ì¥ë‹¨ìœ„", "ìˆ˜ëŸ‰"]
    req_purch = ["ì…ê³ ì¼ì", "ìƒ í’ˆ ëª…", "í¬ì¥ë‹¨ìœ„", "ìˆ˜ëŸ‰"]
    req_stock = ["ìƒ í’ˆ ëª…", "í¬ì¥ë‹¨ìœ„", "ì¬ê³ ìˆ˜ëŸ‰"]

    missing_sales = [c for c in req_sales if c not in sales_raw.columns]
    missing_purch = [c for c in req_purch if c not in purchase_raw.columns]
    missing_stock = [c for c in req_stock if c not in stock_raw.columns]

    sales_date = pd.to_datetime(sales_raw.get("ëª…ì„¸ì¼ì"), errors="coerce")
    purch_date = pd.to_datetime(purchase_raw.get("ì…ê³ ì¼ì"), errors="coerce")
    summary = pd.DataFrame({
        "í•­ëª©": ["í•„ìˆ˜ì»¬ëŸ¼ëˆ„ë½(ë§¤ì¶œ)","í•„ìˆ˜ì»¬ëŸ¼ëˆ„ë½(ë§¤ì…)","í•„ìˆ˜ì»¬ëŸ¼ëˆ„ë½(í˜„ì¬ê³ )","ë‚ ì§œì˜¤ë¥˜(ë§¤ì¶œ)","ë‚ ì§œì˜¤ë¥˜(ë§¤ì…)"],
        "ê±´ìˆ˜": [len(missing_sales), len(missing_purch), len(missing_stock),
                int(sales_date.isna().sum()), int(purch_date.isna().sum())]
    })
    return summary

# ======== ë©”ì¸ ë¡œì§ ========
if sales_file and purchase_file and stock_file:
    sales_df = pd.read_excel(sales_file)  # ë§¤ì¶œ
    purchase_df = pd.read_excel(purchase_file)  # ë§¤ì…(ì…ê³ )
    stock_df = pd.read_excel(stock_file)  # í˜„ì¬ê³ 

    # ì»¬ëŸ¼ ì •ê·œí™”(ë³„ì¹­ ëŒ€ì‘)
    sales_df = normalize_columns(sales_df, {
        "ê±°ë˜ì¼ì": "ëª…ì„¸ì¼ì", "ì¼ì": "ëª…ì„¸ì¼ì", "ë§¤ì¶œì²˜": "ë§¤ ì¶œ ì²˜",
        "ìƒí’ˆëª…": "ìƒ í’ˆ ëª…", "í¬ì¥ ë‹¨ìœ„": "í¬ì¥ë‹¨ìœ„", "ì œì¡°ì‚¬": "ì œ ì¡° ì‚¬", "ì œì•½ì‚¬": "ì œ ì¡° ì‚¬",
        "ê³µê¸‰ì²˜": "ë§¤ ì… ì²˜", "ê±°ë˜ì²˜": "ë§¤ ì… ì²˜", "ë§¤ì…ì²˜": "ë§¤ ì… ì²˜"
    })
    purchase_df = normalize_columns(purchase_df, {
        "ì…ê³ ì¼": "ì…ê³ ì¼ì", "ê±°ë˜ì²˜": "ë§¤ ì… ì²˜", "ë§¤ì…ì²˜": "ë§¤ ì… ì²˜", "ê³µê¸‰ì²˜": "ë§¤ ì… ì²˜",
        "ìƒí’ˆëª…": "ìƒ í’ˆ ëª…", "í¬ì¥ ë‹¨ìœ„": "í¬ì¥ë‹¨ìœ„", "ì œì¡°ì‚¬": "ì œ ì¡° ì‚¬", "ì œì•½ì‚¬": "ì œ ì¡° ì‚¬"
    })
    stock_df = normalize_columns(stock_df, {
        "ê±°ë˜ì²˜": "ë§¤ ì… ì²˜", "ë§¤ì…ì²˜": "ë§¤ ì… ì²˜", "ê³µê¸‰ì²˜": "ë§¤ ì… ì²˜",
        "ìƒí’ˆëª…": "ìƒ í’ˆ ëª…", "í¬ì¥ ë‹¨ìœ„": "í¬ì¥ë‹¨ìœ„", "ì œì¡°ì‚¬": "ì œ ì¡° ì‚¬", "ì œì•½ì‚¬": "ì œ ì¡° ì‚¬",
        "ì¬ê³ ": "ì¬ê³ ìˆ˜ëŸ‰"
    })

    # í•„ìˆ˜ ì»¬ëŸ¼ ì²´í¬ (ë§¤ì…ì²˜ëŠ” í•„ìˆ˜ê°€ ì•„ë‹˜)
    require_columns(sales_df, ["ëª…ì„¸ì¼ì", "ìƒ í’ˆ ëª…", "í¬ì¥ë‹¨ìœ„", "ìˆ˜ëŸ‰"], "ë§¤ì¶œìë£Œ")
    require_columns(purchase_df, ["ì…ê³ ì¼ì", "ìƒ í’ˆ ëª…", "í¬ì¥ë‹¨ìœ„", "ìˆ˜ëŸ‰"], "ë§¤ì…ìë£Œ")
    require_columns(stock_df, ["ìƒ í’ˆ ëª…", "í¬ì¥ë‹¨ìœ„", "ì¬ê³ ìˆ˜ëŸ‰"], "í˜„ì¬ê³ ")

    # ë¬¸ìì—´ ì •ë¦¬
    for df in [sales_df, purchase_df, stock_df]:
        df["ìƒ í’ˆ ëª…"] = to_upper_strip(df["ìƒ í’ˆ ëª…"])
        df["í¬ì¥ë‹¨ìœ„"] = to_upper_strip(df["í¬ì¥ë‹¨ìœ„"])

    # ë‚ ì§œí˜•
    sales_df["ëª…ì„¸ì¼ì"] = pd.to_datetime(sales_df["ëª…ì„¸ì¼ì"], errors="coerce")
    purchase_df["ì…ê³ ì¼ì"] = pd.to_datetime(purchase_df["ì…ê³ ì¼ì"], errors="coerce")

    # ì œì¡°ì‚¬/ë§¤ì…ì²˜ í‘œì¤€í™” ë° ë§¤í•‘ ì ìš©(ë§¤ì…ì²˜ ì—†ì–´ë„ ë¬´ì‹œ)
    for df in [sales_df, purchase_df, stock_df]:
        if "ì œ ì¡° ì‚¬" in df.columns:
            df["ì œ ì¡° ì‚¬"] = clean_party_name(df["ì œ ì¡° ì‚¬"])
        if "ë§¤ ì… ì²˜" in df.columns:
            df["ë§¤ ì… ì²˜"] = clean_party_name(df["ë§¤ ì… ì²˜"])
    # ë§¤í•‘í‘œ ì ìš©
    map_df = None
    if name_map_file is not None:
        try:
            map_df = pd.read_excel(name_map_file) if name_map_file.name.lower().endswith(".xlsx") else pd.read_csv(name_map_file)
        except Exception:
            map_df = None
    if map_df is not None:
        if "ì œ ì¡° ì‚¬" in stock_df.columns:
            stock_df["ì œ ì¡° ì‚¬"] = apply_name_mapping(stock_df["ì œ ì¡° ì‚¬"], map_df)
        if "ë§¤ ì… ì²˜" in stock_df.columns:
            stock_df["ë§¤ ì… ì²˜"] = apply_name_mapping(stock_df["ë§¤ ì… ì²˜"], map_df)

    # ë¶„ì„ ê¸°ê°„
    if mode == "ìë™ (ìµœê·¼ 3ê°œì›”)":
        end_date = sales_df["ëª…ì„¸ì¼ì"].max()
        start_date = end_date - pd.DateOffset(months=3)
    else:
        c3, c4 = st.columns(2)
        with c3:
            start_date = st.date_input("ì‹œì‘ì¼", value=sales_df["ëª…ì„¸ì¼ì"].min().date())
        with c4:
            end_date = st.date_input("ì¢…ë£Œì¼", value=sales_df["ëª…ì„¸ì¼ì"].max().date())
        start_date = pd.to_datetime(start_date)
        end_date = pd.to_datetime(end_date)

    # ===== ë°œì£¼ ê¸°ì¤€: ìµœê·¼ Nì¼ íŒë§¤ëŸ‰(ì´í•©) =====
    max_sale_date = sales_df["ëª…ì„¸ì¼ì"].max()
    nday_start = max_sale_date - pd.Timedelta(days=int(selected_days))
    nday_sales = sales_df[(sales_df["ëª…ì„¸ì¼ì"] > nday_start) & (sales_df["ëª…ì„¸ì¼ì"] <= max_sale_date)]
    nday_qty = nday_sales.groupby(["ìƒ í’ˆ ëª…", "í¬ì¥ë‹¨ìœ„"], as_index=False)["ìˆ˜ëŸ‰"].sum()
    nday_qty.rename(columns={"ìˆ˜ëŸ‰": f"ìµœê·¼{selected_days}ì¼_íŒë§¤ëŸ‰"}, inplace=True)
    nday_qty["ê¸°ì¤€íŒë§¤ëŸ‰"] = nday_qty[f"ìµœê·¼{selected_days}ì¼_íŒë§¤ëŸ‰"].astype(int)

    # í˜„ì¬ê³  ë³‘í•©(ì œì¡°ì‚¬/ë§¤ì…ì²˜ëŠ” ì—†ì„ ìˆ˜ ìˆìŒ)
    cols_to_pull = ["ìƒ í’ˆ ëª…", "í¬ì¥ë‹¨ìœ„", "ì¬ê³ ìˆ˜ëŸ‰"]
    if "ì œ ì¡° ì‚¬" in stock_df.columns: cols_to_pull.append("ì œ ì¡° ì‚¬")
    if "ë§¤ ì… ì²˜" in stock_df.columns: cols_to_pull.append("ë§¤ ì… ì²˜")
    merged = nday_qty.merge(stock_df[cols_to_pull].drop_duplicates(), on=["ìƒ í’ˆ ëª…", "í¬ì¥ë‹¨ìœ„"], how="left")

    # ì œì¡°ì‚¬/ë§¤ì…ì²˜ ë³´ê°•: ìµœê·¼ ë§¤ì… ì´ë ¥ì—ì„œ ê°€ì ¸ì˜¤ê¸° (ì—†ìœ¼ë©´ í†µê³¼)
    purchase_sorted = purchase_df.sort_values("ì…ê³ ì¼ì")
    agg_dict = {}
    if "ì œ ì¡° ì‚¬" in purchase_df.columns: agg_dict["ì œ ì¡° ì‚¬"] = "last"
    if "ë§¤ ì… ì²˜" in purchase_df.columns: agg_dict["ë§¤ ì… ì²˜"] = "last"
    if agg_dict:
        last_info = purchase_sorted.groupby(["ìƒ í’ˆ ëª…", "í¬ì¥ë‹¨ìœ„"]).agg(agg_dict).reset_index()
        merged = merged.merge(last_info, on=["ìƒ í’ˆ ëª…", "í¬ì¥ë‹¨ìœ„"], how="left", suffixes=("", "_ìµœê·¼ì…ê³ "))
        for col in agg_dict.keys():
            if col in merged.columns and f"{col}_ìµœê·¼ì…ê³ " in merged.columns:
                merged[col] = merged[col].fillna(merged[f"{col}_ìµœê·¼ì…ê³ "])
                merged.drop(columns=[f"{col}_ìµœê·¼ì…ê³ "], inplace=True)

    # ìµœê·¼ ì…ê³  ë°˜ì˜(ì˜µì…˜)
    if use_recent_purchase:
        cutoff = purchase_df["ì…ê³ ì¼ì"].max() - pd.Timedelta(days=int(recent_days))
        recent_purchase = purchase_df[purchase_df["ì…ê³ ì¼ì"] >= cutoff]
        recent_in_qty = recent_purchase.groupby(["ìƒ í’ˆ ëª…", "í¬ì¥ë‹¨ìœ„"], as_index=False)["ìˆ˜ëŸ‰"].sum()
        recent_in_qty.rename(columns={"ìˆ˜ëŸ‰": "ìµœê·¼ì…ê³ ìˆ˜ëŸ‰"}, inplace=True)
        merged = merged.merge(recent_in_qty, on=["ìƒ í’ˆ ëª…", "í¬ì¥ë‹¨ìœ„"], how="left")
        merged["ìµœê·¼ì…ê³ ìˆ˜ëŸ‰"] = merged["ìµœê·¼ì…ê³ ìˆ˜ëŸ‰"].fillna(0).astype(int)
    else:
        merged["ìµœê·¼ì…ê³ ìˆ˜ëŸ‰"] = 0

    # ë¶€ì¡±/ê³¼ì¬ê³ /ë°œì£¼ìˆ˜ëŸ‰ ê³„ì‚°
    merged["ì¬ê³ ìˆ˜ëŸ‰"] = merged["ì¬ê³ ìˆ˜ëŸ‰"].fillna(0).astype(int)
    merged["ê¸°ì¤€íŒë§¤ëŸ‰"] = merged["ê¸°ì¤€íŒë§¤ëŸ‰"].fillna(0).astype(int)

    merged["ë¶€ì¡±ìˆ˜ëŸ‰"] = (merged["ê¸°ì¤€íŒë§¤ëŸ‰"] - merged["ì¬ê³ ìˆ˜ëŸ‰"] - merged["ìµœê·¼ì…ê³ ìˆ˜ëŸ‰"]).astype(int)
    merged["ë¶€ì¡±ìˆ˜ëŸ‰"] = merged["ë¶€ì¡±ìˆ˜ëŸ‰"].apply(lambda x: x if x > 0 else 0)

    merged["ê³¼ì¬ê³ "] = (merged["ì¬ê³ ìˆ˜ëŸ‰"] - merged["ê¸°ì¤€íŒë§¤ëŸ‰"]).astype(int)
    merged["ê³¼ì¬ê³ "] = merged["ê³¼ì¬ê³ "].apply(lambda x: x if x > 0 else 0)

    merged["ë°œì£¼ìˆ˜ëŸ‰"] = merged["ë¶€ì¡±ìˆ˜ëŸ‰"]

    # ë³´ê¸° ì˜µì…˜ í•„í„°
    if min_shortage > 0:
        merged = merged[merged["ë¶€ì¡±ìˆ˜ëŸ‰"] >= int(min_shortage)]
    if show_only_to_order:
        merged = merged[merged["ë°œì£¼ìˆ˜ëŸ‰"] > 0]

    # ===== ìƒë‹¨ KPI =====
    k1, k2, k3, k4 = st.columns(4)
    k1.metric("ì´ í’ˆëª©ìˆ˜", f"{len(merged):,}")
    k2.metric("ë°œì£¼ í•„ìš” í’ˆëª©ìˆ˜", f"{(merged['ë°œì£¼ìˆ˜ëŸ‰'] > 0).sum():,}")
    k3.metric("ë¶€ì¡±ìˆ˜ëŸ‰ í•©ê³„", f"{int(merged['ë¶€ì¡±ìˆ˜ëŸ‰'].sum()):,}")
    k4.metric("ê³¼ì¬ê³  í•©ê³„", f"{int(merged['ê³¼ì¬ê³ '].sum()):,}")

    # ===== ë¯¸ë¦¬ë³´ê¸°(í™”ë©´ ì „ìš© ê·¸ë£¹ ê¸°ì¤€) =====
    f1, f2, f3 = st.columns([2, 1, 1])
    with f1:
        keyword = st.text_input("ğŸ” ìƒí’ˆëª… ê²€ìƒ‰(ëŒ€ì†Œë¬¸ì ë¬´ì‹œ)", value="").strip().upper()
    with f2:
        manu_sel = st.multiselect("ì œì¡°ì‚¬ í•„í„°", sorted(pd.Series(merged.get("ì œ ì¡° ì‚¬", pd.Series())).dropna().unique().tolist())) if "ì œ ì¡° ì‚¬" in merged.columns else st.multiselect("ì œì¡°ì‚¬ í•„í„°", [])
    with f3:
        if "ë§¤ ì… ì²˜" in merged.columns and not manufacturer_only:
            supplier_sel = st.multiselect("ë§¤ì…ì²˜ í•„í„°(ë¯¸ë¦¬ë³´ê¸°)", sorted(pd.Series(merged["ë§¤ ì… ì²˜"]).dropna().unique().tolist()))
        else:
            supplier_sel = []
            if "ë§¤ ì… ì²˜" in merged.columns:
                st.caption("â„¹ï¸ ë°œì£¼ì„œ ì–‘ì‹ì—ì„œ ë§¤ì…ì²˜ëŠ” ì œì™¸ë©ë‹ˆë‹¤.")

    view_df = merged.copy()
    if keyword:
        view_df = view_df[view_df["ìƒ í’ˆ ëª…"].str.contains(keyword, na=False)]
    if manu_sel and "ì œ ì¡° ì‚¬" in view_df.columns:
        view_df = view_df[view_df["ì œ ì¡° ì‚¬"].isin(manu_sel)]
    if supplier_sel and "ë§¤ ì… ì²˜" in view_df.columns and not manufacturer_only:
        view_df = view_df[view_df["ë§¤ ì… ì²˜"].isin(supplier_sel)]

    # í™”ë©´ í‘œì‹œ ì»¬ëŸ¼
    base_cols = ["ì œ ì¡° ì‚¬", "ë§¤ ì… ì²˜", "ìƒ í’ˆ ëª…", "í¬ì¥ë‹¨ìœ„",
                 "ì¬ê³ ìˆ˜ëŸ‰", f"ìµœê·¼{selected_days}ì¼_íŒë§¤ëŸ‰", "ê¸°ì¤€íŒë§¤ëŸ‰",
                 "ìµœê·¼ì…ê³ ìˆ˜ëŸ‰", "ë¶€ì¡±ìˆ˜ëŸ‰", "ê³¼ì¬ê³ ", "ë°œì£¼ìˆ˜ëŸ‰"]
    col_order = [c for c in base_cols if c in view_df.columns]
    # ë¯¸ë¦¬ë³´ê¸°ì—ì„œë„ ë§¤ì…ì²˜ ìˆ¨ê¸°ê¸° ì˜µì…˜ ì ìš©
    if manufacturer_only and "ë§¤ ì… ì²˜" in col_order:
        col_order.remove("ë§¤ ì… ì²˜")

    view_df = view_df.drop_duplicates(subset=["ìƒ í’ˆ ëª…", "í¬ì¥ë‹¨ìœ„"]).copy()
    sort_cols = [c for c in ["ì œ ì¡° ì‚¬", "ë§¤ ì… ì²˜", "ìƒ í’ˆ ëª…"] if c in view_df.columns]
    if manufacturer_only and "ë§¤ ì… ì²˜" in sort_cols:
        sort_cols.remove("ë§¤ ì… ì²˜")
    if sort_cols:
        view_df = view_df[col_order].sort_values(sort_cols)
    else:
        view_df = view_df[col_order]

    # ===== í‘œ ìŠ¤íƒ€ì¼ =====
    def style_df(df):
        def hi_short(v):
            try:
                v = int(v); return "background-color: #ffe5e5; font-weight: 700;" if v > 0 else ""
            except: return ""
        def hi_over(v):
            try:
                v = int(v); return "background-color: #eaf4ff;" if v > 0 else ""
            except: return ""
        num_cols = [c for c in [f"ìµœê·¼{selected_days}ì¼_íŒë§¤ëŸ‰","ì¬ê³ ìˆ˜ëŸ‰","ê¸°ì¤€íŒë§¤ëŸ‰","ìµœê·¼ì…ê³ ìˆ˜ëŸ‰","ë¶€ì¡±ìˆ˜ëŸ‰","ê³¼ì¬ê³ ","ë°œì£¼ìˆ˜ëŸ‰"] if c in df.columns]
        styler = df.style.format("{:,}", subset=num_cols)
        if "ë¶€ì¡±ìˆ˜ëŸ‰" in df.columns:
            styler = styler.applymap(hi_short, subset=["ë¶€ì¡±ìˆ˜ëŸ‰"] + (["ë°œì£¼ìˆ˜ëŸ‰"] if "ë°œì£¼ìˆ˜ëŸ‰" in df.columns else []))
        if "ê³¼ì¬ê³ " in df.columns:
            styler = styler.applymap(hi_over, subset=["ê³¼ì¬ê³ "])
        return styler

    st.subheader("ğŸ“Š ë°œì£¼ ëŒ€ìƒ ë¯¸ë¦¬ë³´ê¸°")
    st.dataframe(style_df(view_df), use_container_width=True, height=520)

    # ===== ì—‘ì…€ ë‚´ë³´ë‚´ê¸° =====
    st.divider()
    st.subheader("ğŸ“¥ ë°œì£¼ì„œ ë‚´ë³´ë‚´ê¸°")
    if manufacturer_only:
        st.caption("ì–‘ì‹ì—ì„œ **ë§¤ì…ì²˜ ì—´ì„ ì œì™¸**í•˜ê³ , **ì œì¡°ì‚¬ë³„**ë¡œë§Œ íŒŒì¼/íƒ­ì„ ìƒì„±í•©ë‹ˆë‹¤.")
    else:
        st.caption("ë¯¸ë¦¬ë³´ê¸° ê¸°ì¤€ëŒ€ë¡œ ë‚´ë³´ë‚´ì§€ë§Œ, ê¶Œì¥ ì–‘ì‹ì€ ì œì¡°ì‚¬ ê¸°ì¤€ì…ë‹ˆë‹¤.")

    # ì‹¤ì œ ê·¸ë£¹ í‚¤ì™€ ë‚´ë³´ë‚´ê¸° ì»¬ëŸ¼
    export_df = merged.copy()
    export_cols = [c for c in base_cols if c in export_df.columns]
    if manufacturer_only and "ë§¤ ì… ì²˜" in export_cols:
        export_cols.remove("ë§¤ ì… ì²˜")
    export_df = export_df[export_cols]

    # ê·¸ë£¹í‚¤ ê°•ì œ: ì œì¡°ì‚¬
    if manufacturer_only:
        group_key = ["ì œ ì¡° ì‚¬"] if "ì œ ì¡° ì‚¬" in export_df.columns else ["ìƒ í’ˆ ëª…"]
    else:
        # í™”ë©´ ì˜µì…˜ ë”°ë¥´ë˜, ì‹¤ì œ ì¡´ì¬í•˜ëŠ” ì»¬ëŸ¼ë§Œ
        if group_mode == "ì œì¡°ì‚¬":
            group_key = ["ì œ ì¡° ì‚¬"] if "ì œ ì¡° ì‚¬" in export_df.columns else ["ìƒ í’ˆ ëª…"]
        elif group_mode == "ë§¤ì…ì²˜" and "ë§¤ ì… ì²˜" in export_df.columns:
            group_key = ["ë§¤ ì… ì²˜"]
        else:
            if {"ì œ ì¡° ì‚¬","ë§¤ ì… ì²˜"}.issubset(set(export_df.columns)):
                group_key = ["ì œ ì¡° ì‚¬","ë§¤ ì… ì²˜"]
            else:
                group_key = ["ì œ ì¡° ì‚¬"] if "ì œ ì¡° ì‚¬" in export_df.columns else ["ìƒ í’ˆ ëª…"]

    if export_mode == "ê·¸ë£¹ë³„ ê°œë³„ íŒŒì¼ (ZIP)":
        if st.button("ZIP ë§Œë“¤ê¸°"):
            zip_buffer = io.BytesIO()
            with zipfile.ZipFile(zip_buffer, "w") as zipf:
                for key_vals, group in export_df.groupby(group_key, dropna=False):
                    if not isinstance(key_vals, tuple):
                        key_vals = (key_vals,)
                    title = " - ".join([str(k) if (k is not None and str(k).strip()!='') else "ë¯¸ì§€ì •" for k in key_vals])
                    output = io.BytesIO()
                    with pd.ExcelWriter(output, engine="xlsxwriter") as writer:
                        sheet_df = group.copy()
                        # ë§¤ì…ì²˜ ì»¬ëŸ¼ ê°•ì œ ì œê±°(ì–‘ì‹ ì¼ê´€ì„±)
                        if "ë§¤ ì… ì²˜" in sheet_df.columns:
                            sheet_df = sheet_df.drop(columns=["ë§¤ ì… ì²˜"])
                        write_formatted_sheet(writer, "ë°œì£¼ì„œ", sheet_df)
                    safe_key = title.replace("/", "-")
                    filename = f"{safe_key} ë°œì£¼ì„œ(ìµœê·¼{selected_days}ì¼).xlsx"
                    zipf.writestr(filename, output.getvalue())
            zip_buffer.seek(0)
            st.download_button("ğŸ“¦ ZIP íŒŒì¼ ë‹¤ìš´ë¡œë“œ", data=zip_buffer, file_name=f"ë°œì£¼ì„œ_ì „ì²´_ìµœê·¼{selected_days}ì¼.zip", mime="application/zip")
    else:
        if st.button("ì—‘ì…€(í•œ íŒŒì¼, íƒ­ êµ¬ë¶„) ë§Œë“¤ê¸°"):
            xls_buffer = io.BytesIO()
            with pd.ExcelWriter(xls_buffer, engine="xlsxwriter") as writer:
                for key_vals, group in export_df.groupby(group_key, dropna=False):
                    if not isinstance(key_vals, tuple):
                        key_vals = (key_vals,)
                    title = " - ".join([str(k) if (k is not None and str(k).strip()!='') else "ë¯¸ì§€ì •" for k in key_vals])
                    sheet_name = sanitize_sheet_name(title)
                    sheet_df = group.copy()
                    if "ë§¤ ì… ì²˜" in sheet_df.columns:
                        sheet_df = sheet_df.drop(columns=["ë§¤ ì… ì²˜"])
                    write_formatted_sheet(writer, sheet_name, sheet_df)
            xls_buffer.seek(0)
            st.download_button("ğŸ“„ ì—‘ì…€ ë‹¤ìš´ë¡œë“œ", data=xls_buffer, file_name=f"ë°œì£¼ì„œ_íƒ­êµ¬ë¶„_ìµœê·¼{selected_days}ì¼.xlsx", mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet")

    # ===== ê°„ë‹¨ ê²€ì¦ ìš”ì•½ í‘œì‹œ =====
    with st.expander("ğŸ§ª ë°ì´í„° ê²€ì¦ ìš”ì•½", expanded=False):
        st.dataframe(validate_and_report(sales_df, purchase_df, stock_df), use_container_width=True)
else:
    st.info(
        "ğŸ“‚ **ì¢Œì¸¡ ì‚¬ì´ë“œë°”**ì—ì„œ **ë§¤ì¶œ ìë£Œ, ë§¤ì… ìë£Œ, í˜„ì¬ê³ ** íŒŒì¼ì„ ëª¨ë‘ ì—…ë¡œë“œí•˜ì„¸ìš”.\n\n"
        "ë§¤ì…ì²˜ ì»¬ëŸ¼ì´ ì—†ì–´ë„ **ì œì¡°ì‚¬ ê¸°ì¤€ ë°œì£¼ì„œ**ë¥¼ ìƒì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
    )
