
import streamlit as st
import pandas as pd
import io
import zipfile
from datetime import timedelta

st.set_page_config(page_title="ì‹ ëª…ì•½í’ˆ ìë™ë°œì£¼(ìˆ˜ëŸ‰ ì¤‘ì‹¬)", layout="wide")

# ============= í—¤ë” =============
c1, c2 = st.columns([1, 5])
with c1:
    st.image("ë¡œê³ ë¦¬ë‰´ì–¼.png", width=100)
with c2:
    st.title("ğŸ’Š ì‹ ëª…ì•½í’ˆ ìë™ë°œì£¼ â€“ ìˆ˜ëŸ‰ ì¤‘ì‹¬")
    st.caption("ê°€ê²©/ë‹¨ê°€ ì •ë³´ëŠ” ì „ë¶€ ì œì™¸í•˜ê³ , í˜„ì¬ê³ Â·ë§¤ì¶œìˆ˜ëŸ‰Â·ë§¤ì…ìˆ˜ëŸ‰ ëŒ€ë¹„ ë°œì£¼ìˆ˜ëŸ‰ì—ë§Œ ì§‘ì¤‘í•©ë‹ˆë‹¤.")

st.sidebar.header("ğŸ“‚ íŒŒì¼ ì—…ë¡œë“œ")
sales_file = st.sidebar.file_uploader("ë§¤ì¶œìë£Œ ì—…ë¡œë“œ", type=["xlsx"])
purchase_file = st.sidebar.file_uploader("ë§¤ì…ìë£Œ ì—…ë¡œë“œ", type=["xlsx"])
stock_file = st.sidebar.file_uploader("í˜„ì¬ê³  ì—…ë¡œë“œ", type=["xlsx"])

st.sidebar.divider()
mode = st.sidebar.radio("ğŸ“… ë¶„ì„ ê¸°ê°„", ["ìë™ (ìµœê·¼ 3ê°œì›”)", "ìˆ˜ë™ ì§€ì •"])

group_by_option = st.sidebar.radio("ğŸ“ ë°œì£¼ì„œ ê·¸ë£¹ ê¸°ì¤€", ["ë§¤ ì… ì²˜", "ì œ ì¡° ì‚¬"])

st.sidebar.divider()
use_recent_purchase = st.sidebar.checkbox("ìµœê·¼ ì…ê³ ìˆ˜ëŸ‰ ë°˜ì˜í•˜ì—¬ ê³¼ë°œì£¼ ë°©ì§€", value=True)
recent_days = st.sidebar.number_input("ìµœê·¼ ì…ê³  ë°˜ì˜ ì¼ìˆ˜", min_value=1, max_value=90, value=14, step=1)

st.sidebar.divider()
# =========================
# ë³€ê²½: ë°œì£¼ ê¸°ì¤€ ì„ íƒì„ 1ì¼~1ë…„(365ì¼) ë²”ìœ„ ë“œë¡­ë‹¤ìš´ìœ¼ë¡œ ì œê³µ
# ê¸°ì¤€íŒë§¤ëŸ‰ = ìµœê·¼ Nì¼ ë§¤ì¶œìˆ˜ëŸ‰ í•©ê³„
# =========================
days_options = list(range(1, 366))
days_label_map = {d: f"{d}ì¼" for d in days_options}
selected_days = st.sidebar.selectbox("ë°œì£¼ ê¸°ì¤€(ìµœê·¼ Nì¼ íŒë§¤ëŸ‰)", options=days_options, format_func=lambda x: days_label_map[x], index=29)  # ê¸°ë³¸ 30ì¼

min_shortage = st.sidebar.number_input("ë¶€ì¡±ìˆ˜ëŸ‰ í•˜í•œ(ì´ìƒë§Œ í‘œì‹œ)", min_value=0, value=0, step=1)
show_only_to_order = st.sidebar.checkbox("ë°œì£¼ í•„ìš” í•­ëª©ë§Œ ë³´ê¸°(ë¶€ì¡±ìˆ˜ëŸ‰>0)", value=True)

# ======== ìœ í‹¸ ========
def normalize_columns(df, mapping):
    df = df.copy()
    df.rename(columns={k: v for k, v in mapping.items() if k in df.columns}, inplace=True)
    return df

def require_columns(df, required, name):
    missing = [c for c in required if c not in df.columns]
    if missing:
        st.error(f"{name}ì— í•„ìš”í•œ ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤: {', '.join(missing)}")
        st.stop()

def to_upper_strip(series):
    return series.astype(str).str.strip().str.upper()

# ======== ë©”ì¸ ë¡œì§ ========
if sales_file and purchase_file and stock_file:
    sales_df = pd.read_excel(sales_file)  # ë§¤ì¶œ
    purchase_df = pd.read_excel(purchase_file)  # ë§¤ì…(ì…ê³ )
    stock_df = pd.read_excel(stock_file)  # í˜„ì¬ê³ 

    # ì»¬ëŸ¼ ì •ê·œí™”
    sales_df = normalize_columns(sales_df, {
        "ê±°ë˜ì¼ì": "ëª…ì„¸ì¼ì", "ì¼ì": "ëª…ì„¸ì¼ì", "ë§¤ì¶œì²˜": "ë§¤ ì¶œ ì²˜",
        "ìƒí’ˆëª…": "ìƒ í’ˆ ëª…", "í¬ì¥ ë‹¨ìœ„": "í¬ì¥ë‹¨ìœ„"
    })
    purchase_df = normalize_columns(purchase_df, {
        "ì…ê³ ì¼": "ì…ê³ ì¼ì", "ê±°ë˜ì²˜": "ë§¤ ì… ì²˜", "ìƒí’ˆëª…": "ìƒ í’ˆ ëª…",
        "í¬ì¥ ë‹¨ìœ„": "í¬ì¥ë‹¨ìœ„", "ì œì¡°ì‚¬": "ì œ ì¡° ì‚¬"
    })
    stock_df = normalize_columns(stock_df, {
        "ê±°ë˜ì²˜": "ë§¤ ì… ì²˜", "ìƒí’ˆëª…": "ìƒ í’ˆ ëª…",
        "í¬ì¥ ë‹¨ìœ„": "í¬ì¥ë‹¨ìœ„", "ì œì¡°ì‚¬": "ì œ ì¡° ì‚¬", "ì¬ê³ ": "ì¬ê³ ìˆ˜ëŸ‰"
    })

    # í•„ìˆ˜ ì»¬ëŸ¼ ì²´í¬
    require_columns(sales_df, ["ëª…ì„¸ì¼ì", "ë§¤ ì¶œ ì²˜", "ìƒ í’ˆ ëª…", "í¬ì¥ë‹¨ìœ„", "ìˆ˜ëŸ‰"], "ë§¤ì¶œìë£Œ")
    require_columns(purchase_df, ["ì…ê³ ì¼ì", "ë§¤ ì… ì²˜", "ìƒ í’ˆ ëª…", "ì œ ì¡° ì‚¬", "ìˆ˜ëŸ‰"], "ë§¤ì…ìë£Œ")
    require_columns(stock_df, ["ë§¤ ì… ì²˜", "ì œ ì¡° ì‚¬", "ìƒ í’ˆ ëª…", "í¬ì¥ë‹¨ìœ„", "ì¬ê³ ìˆ˜ëŸ‰"], "í˜„ì¬ê³ ")

    # ë¬¸ìì—´ ì •ë¦¬
    for df in [sales_df, purchase_df, stock_df]:
        df["ìƒ í’ˆ ëª…"] = to_upper_strip(df["ìƒ í’ˆ ëª…"])
        df["í¬ì¥ë‹¨ìœ„"] = to_upper_strip(df["í¬ì¥ë‹¨ìœ„"])

    # ë‚ ì§œí˜•
    sales_df["ëª…ì„¸ì¼ì"] = pd.to_datetime(sales_df["ëª…ì„¸ì¼ì"], errors="coerce")
    purchase_df["ì…ê³ ì¼ì"] = pd.to_datetime(purchase_df["ì…ê³ ì¼ì"], errors="coerce")

    # ë¶„ì„ ê¸°ê°„
    if mode == "ìë™ (ìµœê·¼ 3ê°œì›”)":
        end_date = sales_df["ëª…ì„¸ì¼ì"].max()
        start_date = end_date - pd.DateOffset(months=3)
    else:
        c3, c4 = st.columns(2)
        with c3:
            start_date = st.date_input("ì‹œì‘ì¼", value=sales_df["ëª…ì„¸ì¼ì"].min().date())
        with c4:
            end_date = st.date_input("ì¢…ë£Œì¼", value=sales_df["ëª…ì„¸ì¼ì"].max().date())
        start_date = pd.to_datetime(start_date)
        end_date = pd.to_datetime(end_date)

    sales_period = sales_df[(sales_df["ëª…ì„¸ì¼ì"] >= start_date) & (sales_df["ëª…ì„¸ì¼ì"] <= end_date)]

    # ===== ë°œì£¼ ê¸°ì¤€: ìµœê·¼ Nì¼ íŒë§¤ëŸ‰(ì´í•©) =====
    max_sale_date = sales_df["ëª…ì„¸ì¼ì"].max()
    nday_start = max_sale_date - pd.Timedelta(days=int(selected_days))
    nday_sales = sales_df[(sales_df["ëª…ì„¸ì¼ì"] > nday_start) & (sales_df["ëª…ì„¸ì¼ì"] <= max_sale_date)]
    nday_qty = nday_sales.groupby(["ìƒ í’ˆ ëª…", "í¬ì¥ë‹¨ìœ„"], as_index=False)["ìˆ˜ëŸ‰"].sum()
    nday_qty.rename(columns={"ìˆ˜ëŸ‰": f"ìµœê·¼{selected_days}ì¼_íŒë§¤ëŸ‰"}, inplace=True)
    nday_qty["ê¸°ì¤€íŒë§¤ëŸ‰"] = nday_qty[f"ìµœê·¼{selected_days}ì¼_íŒë§¤ëŸ‰"].astype(int)

    # í˜„ì¬ê³  ë³‘í•©
    merged = nday_qty.merge(stock_df[["ìƒ í’ˆ ëª…", "í¬ì¥ë‹¨ìœ„", "ì¬ê³ ìˆ˜ëŸ‰", "ë§¤ ì… ì²˜", "ì œ ì¡° ì‚¬"]].drop_duplicates(),
                            on=["ìƒ í’ˆ ëª…", "í¬ì¥ë‹¨ìœ„"], how="left")

    # ìµœê·¼ ì…ê³  ë°˜ì˜(ì˜µì…˜)
    if use_recent_purchase:
        cutoff = purchase_df["ì…ê³ ì¼ì"].max() - pd.Timedelta(days=int(recent_days))
        recent_purchase = purchase_df[purchase_df["ì…ê³ ì¼ì"] >= cutoff]
        recent_in_qty = recent_purchase.groupby(["ìƒ í’ˆ ëª…", "í¬ì¥ë‹¨ìœ„"], as_index=False)["ìˆ˜ëŸ‰"].sum()
        recent_in_qty.rename(columns={"ìˆ˜ëŸ‰": "ìµœê·¼ì…ê³ ìˆ˜ëŸ‰"}, inplace=True)
        merged = merged.merge(recent_in_qty, on=["ìƒ í’ˆ ëª…", "í¬ì¥ë‹¨ìœ„"], how="left")
        merged["ìµœê·¼ì…ê³ ìˆ˜ëŸ‰"] = merged["ìµœê·¼ì…ê³ ìˆ˜ëŸ‰"].fillna(0).astype(int)
    else:
        merged["ìµœê·¼ì…ê³ ìˆ˜ëŸ‰"] = 0

    # ë¶€ì¡±/ê³¼ì¬ê³ /ë°œì£¼ìˆ˜ëŸ‰ ê³„ì‚°
    merged["ì¬ê³ ìˆ˜ëŸ‰"] = merged["ì¬ê³ ìˆ˜ëŸ‰"].fillna(0).astype(int)
    merged["ê¸°ì¤€íŒë§¤ëŸ‰"] = merged["ê¸°ì¤€íŒë§¤ëŸ‰"].fillna(0).astype(int)

    merged["ë¶€ì¡±ìˆ˜ëŸ‰"] = (merged["ê¸°ì¤€íŒë§¤ëŸ‰"] - merged["ì¬ê³ ìˆ˜ëŸ‰"] - merged["ìµœê·¼ì…ê³ ìˆ˜ëŸ‰"]).astype(int)
    merged["ë¶€ì¡±ìˆ˜ëŸ‰"] = merged["ë¶€ì¡±ìˆ˜ëŸ‰"].apply(lambda x: x if x > 0 else 0)

    merged["ê³¼ì¬ê³ "] = (merged["ì¬ê³ ìˆ˜ëŸ‰"] - merged["ê¸°ì¤€íŒë§¤ëŸ‰"]).astype(int)
    merged["ê³¼ì¬ê³ "] = merged["ê³¼ì¬ê³ "].apply(lambda x: x if x > 0 else 0)

    merged["ë°œì£¼ìˆ˜ëŸ‰"] = merged["ë¶€ì¡±ìˆ˜ëŸ‰"]  # ê¸°ë³¸ ë¡œì§: ë¶€ì¡±=ë°œì£¼

    # ë³´ê¸° ì˜µì…˜ í•„í„°
    if min_shortage > 0:
        merged = merged[merged["ë¶€ì¡±ìˆ˜ëŸ‰"] >= int(min_shortage)]
    if show_only_to_order:
        merged = merged[merged["ë°œì£¼ìˆ˜ëŸ‰"] > 0]

    # ì¤‘ë³µ ì œê±° ë° ì •ë ¬
    merged = merged.drop_duplicates(subset=["ìƒ í’ˆ ëª…", "í¬ì¥ë‹¨ìœ„"])
    dynamic_cols = ["ì œ ì¡° ì‚¬", "ë§¤ ì… ì²˜", "ìƒ í’ˆ ëª…", "í¬ì¥ë‹¨ìœ„",
                    "ì¬ê³ ìˆ˜ëŸ‰", f"ìµœê·¼{selected_days}ì¼_íŒë§¤ëŸ‰", "ê¸°ì¤€íŒë§¤ëŸ‰",
                    "ìµœê·¼ì…ê³ ìˆ˜ëŸ‰", "ë¶€ì¡±ìˆ˜ëŸ‰", "ê³¼ì¬ê³ ", "ë°œì£¼ìˆ˜ëŸ‰"]
    col_order = [c for c in dynamic_cols if c in merged.columns]
    merged = merged[col_order].sort_values(["ì œ ì¡° ì‚¬", "ë§¤ ì… ì²˜", "ìƒ í’ˆ ëª…"])

    # ===== ìƒë‹¨ KPI =====
    k1, k2, k3, k4 = st.columns(4)
    total_items = len(merged)
    to_order_items = (merged["ë°œì£¼ìˆ˜ëŸ‰"] > 0).sum() if "ë°œì£¼ìˆ˜ëŸ‰" in merged else 0
    total_shortage = int(merged["ë¶€ì¡±ìˆ˜ëŸ‰"].sum()) if "ë¶€ì¡±ìˆ˜ëŸ‰" in merged else 0
    total_over = int(merged["ê³¼ì¬ê³ "].sum()) if "ê³¼ì¬ê³ " in merged else 0

    k1.metric("ì´ í’ˆëª©ìˆ˜", f"{total_items:,}")
    k2.metric("ë°œì£¼ í•„ìš” í’ˆëª©ìˆ˜", f"{to_order_items:,}")
    k3.metric("ë¶€ì¡±ìˆ˜ëŸ‰ í•©ê³„", f"{total_shortage:,}")
    k4.metric("ê³¼ì¬ê³  í•©ê³„", f"{total_over:,}")

    # ===== í•„í„°(ê²€ìƒ‰/ë“œë¡­ë‹¤ìš´) =====
    f1, f2, f3 = st.columns([2, 1, 1])
    with f1:
        keyword = st.text_input("ğŸ” ìƒí’ˆëª… ê²€ìƒ‰(ëŒ€ì†Œë¬¸ì ë¬´ì‹œ)", value="").strip().upper()
    with f2:
        manu_sel = st.multiselect("ì œì¡°ì‚¬ í•„í„°", sorted(merged["ì œ ì¡° ì‚¬"].dropna().unique().tolist()))
    with f3:
        supplier_sel = st.multiselect("ë§¤ì…ì²˜ í•„í„°", sorted(merged["ë§¤ ì… ì²˜"].dropna().unique().tolist()))

    view_df = merged.copy()
    if keyword:
        view_df = view_df[view_df["ìƒ í’ˆ ëª…"].str.contains(keyword, na=False)]
    if manu_sel:
        view_df = view_df[view_df["ì œ ì¡° ì‚¬"].isin(manu_sel)]
    if supplier_sel:
        view_df = view_df[view_df["ë§¤ ì… ì²˜"].isin(supplier_sel)]

    # ===== í‘œ ìŠ¤íƒ€ì¼(ê°€ë…ì„± ê°•í™”) =====
    def style_df(df):
        def highlight_shortage(v):
            if pd.isna(v):
                return ""
            try:
                v = int(v)
            except Exception:
                return ""
            if v > 0:
                return "background-color: #ffe5e5; font-weight: 700;"
            return ""
        def highlight_over(v):
            if pd.isna(v):
                return ""
            try:
                v = int(v)
            except Exception:
                return ""
            if v > 0:
                return "background-color: #eaf4ff;"
            return ""

        numeric_cols = [c for c in [f"ìµœê·¼{selected_days}ì¼_íŒë§¤ëŸ‰","ì¬ê³ ìˆ˜ëŸ‰","ê¸°ì¤€íŒë§¤ëŸ‰","ìµœê·¼ì…ê³ ìˆ˜ëŸ‰","ë¶€ì¡±ìˆ˜ëŸ‰","ê³¼ì¬ê³ ","ë°œì£¼ìˆ˜ëŸ‰"] if c in df.columns]
        styler = df.style.format("{:,}", subset=numeric_cols)
        if "ë¶€ì¡±ìˆ˜ëŸ‰" in df.columns:
            styler = styler.applymap(highlight_shortage, subset=["ë¶€ì¡±ìˆ˜ëŸ‰", "ë°œì£¼ìˆ˜ëŸ‰"] if "ë°œì£¼ìˆ˜ëŸ‰" in df.columns else ["ë¶€ì¡±ìˆ˜ëŸ‰"])
        if "ê³¼ì¬ê³ " in df.columns:
            styler = styler.applymap(highlight_over, subset=["ê³¼ì¬ê³ "])
        return styler

    st.subheader("ğŸ“Š ë°œì£¼ ëŒ€ìƒ ë¯¸ë¦¬ë³´ê¸°")
    st.dataframe(style_df(view_df), use_container_width=True, height=520)

    # ===== ZIP ë‚´ë³´ë‚´ê¸° =====
    st.divider()
    st.subheader("ğŸ“¥ ë°œì£¼ì„œ ì¼ê´„ ë‹¤ìš´ë¡œë“œ (ZIP)")
    st.caption("ì„ íƒí•œ ê·¸ë£¹ ê¸°ì¤€ìœ¼ë¡œ ì‹œíŠ¸ë¥¼ êµ¬ì„±í•œ ê°œë³„ Excel íŒŒì¼ì„ ZIPìœ¼ë¡œ ë¬¶ì–´ ì œê³µí•©ë‹ˆë‹¤. (ê°€ê²©/ë‹¨ê°€ ì—´ ì—†ìŒ)")
    if st.button("ZIP ë§Œë“¤ê¸°"):
        zip_buffer = io.BytesIO()
        with zipfile.ZipFile(zip_buffer, "w") as zipf:
            # ê·¸ë£¹í•‘
            for key, group in merged.groupby(group_by_option):
                output = io.BytesIO()
                with pd.ExcelWriter(output, engine="xlsxwriter") as writer:
                    sheet_df = group.copy()
                    sheet_df = sheet_df[[c for c in col_order if c in sheet_df.columns]]
                    sheet_df.to_excel(writer, index=False, sheet_name="ë°œì£¼ì„œ")
                    ws = writer.sheets["ë°œì£¼ì„œ"]
                    for i, col in enumerate(sheet_df.columns):
                        maxlen = max(sheet_df[col].astype(str).map(len).max(), len(col))
                        ws.set_column(i, i, min(maxlen + 2, 40))
                safe_key = str(key).replace("/", "-")
                filename = f"{safe_key} ë°œì£¼ì„œ(ìµœê·¼{selected_days}ì¼).xlsx"
                zipf.writestr(filename, output.getvalue())
        zip_buffer.seek(0)
        st.download_button("ğŸ“¦ ZIP íŒŒì¼ ë‹¤ìš´ë¡œë“œ", data=zip_buffer, file_name=f"ë°œì£¼ì„œ_ì „ì²´_ìµœê·¼{selected_days}ì¼.zip", mime="application/zip")
else:
    st.info("ğŸ“‚ ì‚¬ì´ë“œë°”ì—ì„œ **ë§¤ì¶œìë£Œ, ë§¤ì…ìë£Œ, í˜„ì¬ê³ ** íŒŒì¼ì„ ëª¨ë‘ ì—…ë¡œë“œí•˜ì„¸ìš”.")
