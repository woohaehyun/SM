
import streamlit as st
import pandas as pd
import io
import zipfile
import os
import re
from datetime import timedelta

st.set_page_config(page_title="ì‹ ëª…ì•½í’ˆ ìë™ë°œì£¼(ìˆ˜ëŸ‰ ì¤‘ì‹¬)", layout="wide")

# ============= ì‚¬ì´ë“œë°” / í—¤ë” =============
st.sidebar.header("ğŸ“‚ íŒŒì¼ ì—…ë¡œë“œ")
sales_file = st.sidebar.file_uploader("ë§¤ì¶œìë£Œ ì—…ë¡œë“œ", type=["xlsx"])
purchase_file = st.sidebar.file_uploader("ë§¤ì…ìë£Œ ì—…ë¡œë“œ", type=["xlsx"])
stock_file = st.sidebar.file_uploader("í˜„ì¬ê³  ì—…ë¡œë“œ", type=["xlsx"])
logo_upload = st.sidebar.file_uploader("ë¡œê³  ì´ë¯¸ì§€(ì„ íƒ)", type=["png","jpg","jpeg","webp"])

c1, c2 = st.columns([1, 5])
with c1:
    try:
        if logo_upload is not None:
            st.image(logo_upload, width=100)
        elif os.path.exists("ë¡œê³ ë¦¬ë‰´ì–¼.png"):
            st.image("ë¡œê³ ë¦¬ë‰´ì–¼.png", width=300)
        else:
            st.empty()
    except Exception:
        st.empty()
with c2:
    st.title("ğŸ’Š ì‹ ëª…ì•½í’ˆ ìë™ë°œì£¼")
    st.caption("ì—‘ì…€ ì¶œë ¥ ì§€ì›.")

st.sidebar.divider()
mode = st.sidebar.radio("ğŸ“… ë¶„ì„ ê¸°ê°„", ["ìë™ (ìµœê·¼ 3ê°œì›”)", "ìˆ˜ë™ ì§€ì •"])

group_by_option = st.sidebar.radio("ğŸ“ ë°œì£¼ì„œ ê·¸ë£¹ ê¸°ì¤€", ["ë§¤ ì… ì²˜", "ì œ ì¡° ì‚¬"])

st.sidebar.divider()
use_recent_purchase = st.sidebar.checkbox("ìµœê·¼ ì…ê³ ìˆ˜ëŸ‰ ë°˜ì˜í•˜ì—¬ ê³¼ë°œì£¼ ë°©ì§€", value=True)
recent_days = st.sidebar.number_input("ìµœê·¼ ì…ê³  ë°˜ì˜ ì¼ìˆ˜", min_value=1, max_value=90, value=14, step=1)

st.sidebar.divider()
days_options = list(range(1, 366))
days_label_map = {d: f"{d}ì¼" for d in days_options}
selected_days = st.sidebar.selectbox("ë°œì£¼ ê¸°ì¤€(ìµœê·¼ Nì¼ íŒë§¤ëŸ‰)", options=days_options, format_func=lambda x: days_label_map[x], index=29)  # ê¸°ë³¸ 30ì¼

min_shortage = st.sidebar.number_input("ë¶€ì¡±ìˆ˜ëŸ‰ í•˜í•œ(ì´ìƒë§Œ í‘œì‹œ)", min_value=0, value=0, step=1)
show_only_to_order = st.sidebar.checkbox("ë°œì£¼ í•„ìš” í•­ëª©ë§Œ ë³´ê¸°(ë¶€ì¡±ìˆ˜ëŸ‰>0)", value=True)

st.sidebar.divider()
export_mode = st.sidebar.radio("ì—‘ì…€ ë‚´ë³´ë‚´ê¸° ë°©ì‹", ["ê·¸ë£¹ë³„ ê°œë³„ íŒŒì¼ (ZIP)", "í•œ íŒŒì¼(íƒ­ êµ¬ë¶„)"], index=1)

# ======== ìœ í‹¸ ========
def normalize_columns(df, mapping):
    df = df.copy()
    df.rename(columns={k: v for k, v in mapping.items() if k in df.columns}, inplace=True)
    return df

def require_columns(df, required, name):
    missing = [c for c in required if c not in df.columns]
    if missing:
        st.error(f"{name}ì— í•„ìš”í•œ ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤: {', '.join(missing)}")
        st.stop()

def to_upper_strip(series):
    return series.astype(str).str.strip().str.upper()

def clean_party_name(series):
    # ìƒí˜¸ëª… í‘œì¤€í™”: ê³µë°± ì •ë¦¬, (ì£¼)/ãˆœ/ì£¼ì‹íšŒì‚¬ ë“± ì œê±°, ì—°ì†ê³µë°± ì¶•ì†Œ
    rep = [
        ("ãˆœ", ""), ("(ì£¼)", ""), ("ì£¼ì‹íšŒì‚¬", ""), ("(ìœ )", ""), ("ìœ í•œíšŒì‚¬", ""),
        ("(ì¬)", ""), ("ì¬ë‹¨ë²•ì¸", ""), ("(ì‚¬)", ""), ("ì‚¬ë‹¨ë²•ì¸", "")
    ]
    s = series.astype(str).str.upper()
    for a,b in rep:
        s = s.str.replace(a, b, regex=False)
    s = s.str.replace(r"\s+", " ", regex=True).str.strip()
    return s

def apply_name_mapping(series, mapping_df):
    if mapping_df is None:
        return series
    # mapping_df expects columns: from, to
    m = mapping_df.copy()
    m.columns = [c.strip().lower() for c in m.columns]
    if not set(["from", "to"]).issubset(set(m.columns)):
        return series
    # Standardize incoming series and 'from'
    s_clean = series.astype(str).str.upper().str.strip()
    m["from"] = m["from"].astype(str).str.upper().str.strip()
    m["to"] = m["to"].astype(str).str.strip()
    map_dict = dict(zip(m["from"], m["to"]))
    return s_clean.map(map_dict).fillna(series)

def safe_mode(series):
    # ìµœë¹ˆê°’ ë°˜í™˜(ë™ë¥ ì¼ ë•Œ ì²«ë²ˆì§¸)
    s = series.dropna()
    if s.empty:
        return None
    return s.mode().iloc[0]

def sanitize_sheet_name(name: str) -> str:
    if name is None or str(name).strip() == "":
        return "ë¯¸ì§€ì •"
    s = str(name)
    # Invalid chars: []:*?/\
    s = re.sub(r"[\[\]\*\?/\\:]", "-", s)
    return s[:31]  # Excel sheet name limit

def write_formatted_sheet(writer, sheet_name, df):
    # ì‹œíŠ¸ ì“°ê¸° + ê°€ë…ì„± ì„œì‹
    df = df.copy()
    df.to_excel(writer, index=False, sheet_name=sheet_name)
    workbook  = writer.book
    ws = writer.sheets[sheet_name]

    # ê¸°ë³¸ ì„œì‹
    header_fmt = workbook.add_format({"bold": True, "bg_color": "#F2F4F7", "border": 1, "align": "center", "valign": "vcenter"})
    num_fmt    = workbook.add_format({"num_format": "#,##0"})
    strong_fmt = workbook.add_format({"bg_color": "#FFE5E5", "bold": True})
    over_fmt   = workbook.add_format({"bg_color": "#EAF4FF"})
    base_fmt   = workbook.add_format({"text_wrap": False})

    # í—¤ë” ì„œì‹ ì ìš©
    for col_idx, col in enumerate(df.columns):
        ws.write(0, col_idx, col, header_fmt)

    # ì—´ ë„ˆë¹„ ìë™ + ìˆ«ìì„œì‹ ì ìš©
    for i, col in enumerate(df.columns):
        try:
            maxlen = max(df[col].astype(str).map(len).max(), len(col))
        except Exception:
            maxlen = len(col)
        ws.set_column(i, i, min(maxlen + 2, 40), num_fmt if pd.api.types.is_numeric_dtype(df[col]) else base_fmt)

    # í–‰ ë†’ì´, ê³ ì •, í•„í„°
    ws.set_default_row(20)
    ws.set_row(0, 24)
    ws.freeze_panes(1, 0)
    ws.autofilter(0, 0, len(df), len(df.columns)-1)

    # ì¡°ê±´ë¶€ ì„œì‹(ë¶€ì¡±/ë°œì£¼ ê°•ì¡°, ê³¼ì¬ê³  ì—°íŒŒë‘)
    col_map = {c:i for i,c in enumerate(df.columns)}
    last_row = len(df)
    if "ë¶€ì¡±ìˆ˜ëŸ‰" in col_map:
        i = col_map["ë¶€ì¡±ìˆ˜ëŸ‰"]
        ws.conditional_format(1, i, last_row, i, {"type": "cell", "criteria": ">", "value": 0, "format": strong_fmt})
    if "ë°œì£¼ìˆ˜ëŸ‰" in col_map:
        i = col_map["ë°œì£¼ìˆ˜ëŸ‰"]
        ws.conditional_format(1, i, last_row, i, {"type": "cell", "criteria": ">", "value": 0, "format": strong_fmt})
    if "ê³¼ì¬ê³ " in col_map:
        i = col_map["ê³¼ì¬ê³ "]
        ws.conditional_format(1, i, last_row, i, {"type": "cell", "criteria": ">", "value": 0, "format": over_fmt})

# ======== ë©”ì¸ ë¡œì§ ========
if sales_file and purchase_file and stock_file:
    sales_df = pd.read_excel(sales_file)  # ë§¤ì¶œ
    purchase_df = pd.read_excel(purchase_file)  # ë§¤ì…(ì…ê³ )
    stock_df = pd.read_excel(stock_file)  # í˜„ì¬ê³ 

    # ì»¬ëŸ¼ ì •ê·œí™”(ì—¬ëŸ¬ ë³„ì¹­ ëŒ€ì‘)
    sales_df = normalize_columns(sales_df, {
        "ê±°ë˜ì¼ì": "ëª…ì„¸ì¼ì", "ì¼ì": "ëª…ì„¸ì¼ì", "ë§¤ì¶œì²˜": "ë§¤ ì¶œ ì²˜",
        "ìƒí’ˆëª…": "ìƒ í’ˆ ëª…", "í¬ì¥ ë‹¨ìœ„": "í¬ì¥ë‹¨ìœ„", "ì œì¡°ì‚¬": "ì œ ì¡° ì‚¬", "ì œì•½ì‚¬": "ì œ ì¡° ì‚¬",
        "ê³µê¸‰ì²˜": "ë§¤ ì… ì²˜", "ê±°ë˜ì²˜": "ë§¤ ì… ì²˜", "ë§¤ì…ì²˜": "ë§¤ ì… ì²˜"
    })
    purchase_df = normalize_columns(purchase_df, {
        "ì…ê³ ì¼": "ì…ê³ ì¼ì", "ê±°ë˜ì²˜": "ë§¤ ì… ì²˜", "ë§¤ì…ì²˜": "ë§¤ ì… ì²˜", "ê³µê¸‰ì²˜": "ë§¤ ì… ì²˜",
        "ìƒí’ˆëª…": "ìƒ í’ˆ ëª…", "í¬ì¥ ë‹¨ìœ„": "í¬ì¥ë‹¨ìœ„", "ì œì¡°ì‚¬": "ì œ ì¡° ì‚¬", "ì œì•½ì‚¬": "ì œ ì¡° ì‚¬"
    })
    stock_df = normalize_columns(stock_df, {
        "ê±°ë˜ì²˜": "ë§¤ ì… ì²˜", "ë§¤ì…ì²˜": "ë§¤ ì… ì²˜", "ê³µê¸‰ì²˜": "ë§¤ ì… ì²˜",
        "ìƒí’ˆëª…": "ìƒ í’ˆ ëª…", "í¬ì¥ ë‹¨ìœ„": "í¬ì¥ë‹¨ìœ„", "ì œì¡°ì‚¬": "ì œ ì¡° ì‚¬", "ì œì•½ì‚¬": "ì œ ì¡° ì‚¬",
        "ì¬ê³ ": "ì¬ê³ ìˆ˜ëŸ‰"
    })

    # ëª…ì¹­ ë§¤í•‘í‘œ(ì„ íƒ) ë¡œë“œ
    map_df = None
    if name_map_file is not None:
        try:
            if name_map_file.name.lower().endswith(".csv"):
                map_df = pd.read_csv(name_map_file)
            else:
                map_df = pd.read_excel(name_map_file)
        except Exception:
            map_df = None

    # í•„ìˆ˜ ì»¬ëŸ¼ ì²´í¬
    require_columns(sales_df, ["ëª…ì„¸ì¼ì", "ìƒ í’ˆ ëª…", "í¬ì¥ë‹¨ìœ„", "ìˆ˜ëŸ‰"], "ë§¤ì¶œìë£Œ")
    require_columns(purchase_df, ["ì…ê³ ì¼ì", "ìƒ í’ˆ ëª…", "í¬ì¥ë‹¨ìœ„", "ìˆ˜ëŸ‰"], "ë§¤ì…ìë£Œ")
    require_columns(stock_df, ["ìƒ í’ˆ ëª…", "í¬ì¥ë‹¨ìœ„", "ì¬ê³ ìˆ˜ëŸ‰"], "í˜„ì¬ê³ ")

    # ë¬¸ìì—´ ì •ë¦¬
    for df in [sales_df, purchase_df, stock_df]:
        df["ìƒ í’ˆ ëª…"] = to_upper_strip(df["ìƒ í’ˆ ëª…"])
        df["í¬ì¥ë‹¨ìœ„"] = to_upper_strip(df["í¬ì¥ë‹¨ìœ„"])

    # ë‚ ì§œí˜•
    sales_df["ëª…ì„¸ì¼ì"] = pd.to_datetime(sales_df["ëª…ì„¸ì¼ì"], errors="coerce")
    purchase_df["ì…ê³ ì¼ì"] = pd.to_datetime(purchase_df["ì…ê³ ì¼ì"], errors="coerce")

    # ì œì¡°ì‚¬/ë§¤ì…ì²˜ í‘œì¤€í™” ë° ë§¤í•‘ ì ìš©
    for df in [sales_df, purchase_df, stock_df]:
        if "ì œ ì¡° ì‚¬" in df.columns:
            df["ì œ ì¡° ì‚¬"] = clean_party_name(df["ì œ ì¡° ì‚¬"])
            df["ì œ ì¡° ì‚¬"] = apply_name_mapping(df["ì œ ì¡° ì‚¬"], map_df)
        if "ë§¤ ì… ì²˜" in df.columns:
            df["ë§¤ ì… ì²˜"] = clean_party_name(df["ë§¤ ì… ì²˜"])
            df["ë§¤ ì… ì²˜"] = apply_name_mapping(df["ë§¤ ì… ì²˜"], map_df)

    # ë¶„ì„ ê¸°ê°„
    if mode == "ìë™ (ìµœê·¼ 3ê°œì›”)":
        end_date = sales_df["ëª…ì„¸ì¼ì"].max()
        start_date = end_date - pd.DateOffset(months=3)
    else:
        c3, c4 = st.columns(2)
        with c3:
            start_date = st.date_input("ì‹œì‘ì¼", value=sales_df["ëª…ì„¸ì¼ì"].min().date())
        with c4:
            end_date = st.date_input("ì¢…ë£Œì¼", value=sales_df["ëª…ì„¸ì¼ì"].max().date())
        start_date = pd.to_datetime(start_date)
        end_date = pd.to_datetime(end_date)

    # ===== ë°œì£¼ ê¸°ì¤€: ìµœê·¼ Nì¼ íŒë§¤ëŸ‰(ì´í•©) =====
    max_sale_date = sales_df["ëª…ì„¸ì¼ì"].max()
    nday_start = max_sale_date - pd.Timedelta(days=int(selected_days))
    nday_sales = sales_df[(sales_df["ëª…ì„¸ì¼ì"] > nday_start) & (sales_df["ëª…ì„¸ì¼ì"] <= max_sale_date)]
    nday_qty = nday_sales.groupby(["ìƒ í’ˆ ëª…", "í¬ì¥ë‹¨ìœ„"], as_index=False)["ìˆ˜ëŸ‰"].sum()
    nday_qty.rename(columns={"ìˆ˜ëŸ‰": f"ìµœê·¼{selected_days}ì¼_íŒë§¤ëŸ‰"}, inplace=True)
    nday_qty["ê¸°ì¤€íŒë§¤ëŸ‰"] = nday_qty[f"ìµœê·¼{selected_days}ì¼_íŒë§¤ëŸ‰"].astype(int)

    # í˜„ì¬ê³  ë³‘í•©(ì œì¡°ì‚¬/ë§¤ì…ì²˜ëŠ” stock_dfì— ì—†ì„ ìˆ˜ ìˆìŒ)
    merged = nday_qty.merge(
        stock_df[["ìƒ í’ˆ ëª…", "í¬ì¥ë‹¨ìœ„", "ì¬ê³ ìˆ˜ëŸ‰"]].drop_duplicates(),
        on=["ìƒ í’ˆ ëª…", "í¬ì¥ë‹¨ìœ„"], how="left"
    )

    # ===== ì œì¡°ì‚¬/ë§¤ì…ì²˜ ë³´ê°• ë¡œì§ =====
    # 1) ìµœê·¼ ì…ê³  ê¸°ì¤€ ê°€ì¥ ìµœê·¼ ë ˆì½”ë“œë¡œ ë³´ê°•
    purchase_sorted = purchase_df.sort_values("ì…ê³ ì¼ì")
    agg_dict = {}
    if "ì œ ì¡° ì‚¬" in purchase_df.columns:
        agg_dict["ì œ ì¡° ì‚¬"] = "last"
    if "ë§¤ ì… ì²˜" in purchase_df.columns:
        agg_dict["ë§¤ ì… ì²˜"] = "last"
    if agg_dict:
        last_info = purchase_sorted.groupby(["ìƒ í’ˆ ëª…", "í¬ì¥ë‹¨ìœ„"]).agg(agg_dict).reset_index()
        merged = merged.merge(last_info, on=["ìƒ í’ˆ ëª…", "í¬ì¥ë‹¨ìœ„"], how="left")

        # 2) ìƒí’ˆëª… ê¸°ì¤€ ë³´ê°•
        last_info_by_name = purchase_sorted.groupby(["ìƒ í’ˆ ëª…"]).agg(agg_dict).reset_index()
        merged = merged.merge(last_info_by_name, on=["ìƒ í’ˆ ëª…"], how="left", suffixes=("", "_ì´ë¦„ê¸°ì¤€"))
        for col in ["ì œ ì¡° ì‚¬", "ë§¤ ì… ì²˜"]:
            if col in merged.columns and f"{col}_ì´ë¦„ê¸°ì¤€" in merged.columns:
                merged[col] = merged[col].fillna(merged[f"{col}_ì´ë¦„ê¸°ì¤€"])
                merged.drop(columns=[f"{col}_ì´ë¦„ê¸°ì¤€"], inplace=True)

    # ìµœê·¼ ì…ê³  ë°˜ì˜(ì˜µì…˜)
    if use_recent_purchase:
        cutoff = purchase_df["ì…ê³ ì¼ì"].max() - pd.Timedelta(days=int(recent_days))
        recent_purchase = purchase_df[purchase_df["ì…ê³ ì¼ì"] >= cutoff]
        recent_in_qty = recent_purchase.groupby(["ìƒ í’ˆ ëª…", "í¬ì¥ë‹¨ìœ„"], as_index=False)["ìˆ˜ëŸ‰"].sum()
        recent_in_qty.rename(columns={"ìˆ˜ëŸ‰": "ìµœê·¼ì…ê³ ìˆ˜ëŸ‰"}, inplace=True)
        merged = merged.merge(recent_in_qty, on=["ìƒ í’ˆ ëª…", "í¬ì¥ë‹¨ìœ„"], how="left")
        merged["ìµœê·¼ì…ê³ ìˆ˜ëŸ‰"] = merged["ìµœê·¼ì…ê³ ìˆ˜ëŸ‰"].fillna(0).astype(int)
    else:
        merged["ìµœê·¼ì…ê³ ìˆ˜ëŸ‰"] = 0

    # ë¶€ì¡±/ê³¼ì¬ê³ /ë°œì£¼ìˆ˜ëŸ‰ ê³„ì‚°
    merged["ì¬ê³ ìˆ˜ëŸ‰"] = merged["ì¬ê³ ìˆ˜ëŸ‰"].fillna(0).astype(int)
    merged["ê¸°ì¤€íŒë§¤ëŸ‰"] = merged["ê¸°ì¤€íŒë§¤ëŸ‰"].fillna(0).astype(int)

    merged["ë¶€ì¡±ìˆ˜ëŸ‰"] = (merged["ê¸°ì¤€íŒë§¤ëŸ‰"] - merged["ì¬ê³ ìˆ˜ëŸ‰"] - merged["ìµœê·¼ì…ê³ ìˆ˜ëŸ‰"]).astype(int)
    merged["ë¶€ì¡±ìˆ˜ëŸ‰"] = merged["ë¶€ì¡±ìˆ˜ëŸ‰"].apply(lambda x: x if x > 0 else 0)

    merged["ê³¼ì¬ê³ "] = (merged["ì¬ê³ ìˆ˜ëŸ‰"] - merged["ê¸°ì¤€íŒë§¤ëŸ‰"]).astype(int)
    merged["ê³¼ì¬ê³ "] = merged["ê³¼ì¬ê³ "].apply(lambda x: x if x > 0 else 0)

    merged["ë°œì£¼ìˆ˜ëŸ‰"] = merged["ë¶€ì¡±ìˆ˜ëŸ‰"]

    # ë³´ê¸° ì˜µì…˜ í•„í„°
    if min_shortage > 0:
        merged = merged[merged["ë¶€ì¡±ìˆ˜ëŸ‰"] >= int(min_shortage)]
    if show_only_to_order:
        merged = merged[merged["ë°œì£¼ìˆ˜ëŸ‰"] > 0]

    # ì •ë ¬ ë° ì»¬ëŸ¼ ìˆœì„œ
    merged = merged.drop_duplicates(subset=["ìƒ í’ˆ ëª…", "í¬ì¥ë‹¨ìœ„"])
    dynamic_cols = ["ì œ ì¡° ì‚¬", "ë§¤ ì… ì²˜", "ìƒ í’ˆ ëª…", "í¬ì¥ë‹¨ìœ„",
                    "ì¬ê³ ìˆ˜ëŸ‰", f"ìµœê·¼{selected_days}ì¼_íŒë§¤ëŸ‰", "ê¸°ì¤€íŒë§¤ëŸ‰",
                    "ìµœê·¼ì…ê³ ìˆ˜ëŸ‰", "ë¶€ì¡±ìˆ˜ëŸ‰", "ê³¼ì¬ê³ ", "ë°œì£¼ìˆ˜ëŸ‰"]
    col_order = [c for c in dynamic_cols if c in merged.columns]
    # ì œì¡°ì‚¬/ë§¤ì…ì²˜ ì •ë ¬ ì‹œ Noneì„ ë’¤ë¡œ
    if "ì œ ì¡° ì‚¬" in merged.columns:
        merged["ì œ ì¡° ì‚¬"] = merged["ì œ ì¡° ì‚¬"].fillna("")
    if "ë§¤ ì… ì²˜" in merged.columns:
        merged["ë§¤ ì… ì²˜"] = merged["ë§¤ ì… ì²˜"].fillna("")
    merged = merged[col_order].sort_values(["ì œ ì¡° ì‚¬", "ë§¤ ì… ì²˜", "ìƒ í’ˆ ëª…"])

    # ===== ìƒë‹¨ KPI =====
    k1, k2, k3, k4 = st.columns(4)
    k1.metric("ì´ í’ˆëª©ìˆ˜", f"{len(merged):,}")
    k2.metric("ë°œì£¼ í•„ìš” í’ˆëª©ìˆ˜", f"{(merged['ë°œì£¼ìˆ˜ëŸ‰'] > 0).sum():,}")
    k3.metric("ë¶€ì¡±ìˆ˜ëŸ‰ í•©ê³„", f"{int(merged['ë¶€ì¡±ìˆ˜ëŸ‰'].sum()):,}")
    k4.metric("ê³¼ì¬ê³  í•©ê³„", f"{int(merged['ê³¼ì¬ê³ '].sum()):,}")

    # ===== í•„í„° =====
    f1, f2, f3 = st.columns([2, 1, 1])
    with f1:
        keyword = st.text_input("ğŸ” ìƒí’ˆëª… ê²€ìƒ‰(ëŒ€ì†Œë¬¸ì ë¬´ì‹œ)", value="").strip().upper()
    with f2:
        manu_sel = st.multiselect("ì œì¡°ì‚¬ í•„í„°", sorted(pd.Series(merged.get("ì œ ì¡° ì‚¬", pd.Series())).dropna().unique().tolist()))
    with f3:
        supplier_sel = st.multiselect("ë§¤ì…ì²˜ í•„í„°", sorted(pd.Series(merged.get("ë§¤ ì… ì²˜", pd.Series())).dropna().unique().tolist()))

    view_df = merged.copy()
    if keyword:
        view_df = view_df[view_df["ìƒ í’ˆ ëª…"].str.contains(keyword, na=False)]
    if manu_sel and "ì œ ì¡° ì‚¬" in view_df.columns:
        view_df = view_df[view_df["ì œ ì¡° ì‚¬"].isin(manu_sel)]
    if supplier_sel and "ë§¤ ì… ì²˜" in view_df.columns:
        view_df = view_df[view_df["ë§¤ ì… ì²˜"].isin(supplier_sel)]

    # ===== í‘œ ìŠ¤íƒ€ì¼ =====
    def style_df(df):
        def highlight_shortage(v):
            try:
                v = int(v)
                return "background-color: #ffe5e5; font-weight: 700;" if v > 0 else ""
            except Exception:
                return ""
        def highlight_over(v):
            try:
                v = int(v)
                return "background-color: #eaf4ff;" if v > 0 else ""
            except Exception:
                return ""

        numeric_cols = [c for c in [f"ìµœê·¼{selected_days}ì¼_íŒë§¤ëŸ‰","ì¬ê³ ìˆ˜ëŸ‰","ê¸°ì¤€íŒë§¤ëŸ‰","ìµœê·¼ì…ê³ ìˆ˜ëŸ‰","ë¶€ì¡±ìˆ˜ëŸ‰","ê³¼ì¬ê³ ","ë°œì£¼ìˆ˜ëŸ‰"] if c in df.columns]
        styler = df.style.format("{:,}", subset=numeric_cols)
        if "ë¶€ì¡±ìˆ˜ëŸ‰" in df.columns:
            styler = styler.applymap(highlight_shortage, subset=["ë¶€ì¡±ìˆ˜ëŸ‰", "ë°œì£¼ìˆ˜ëŸ‰"] if "ë°œì£¼ìˆ˜ëŸ‰" in df.columns else ["ë¶€ì¡±ìˆ˜ëŸ‰"])
        if "ê³¼ì¬ê³ " in df.columns:
            styler = styler.applymap(highlight_over, subset=["ê³¼ì¬ê³ "])
        return styler

    st.subheader("ğŸ“Š ë°œì£¼ ëŒ€ìƒ ë¯¸ë¦¬ë³´ê¸°")
    st.dataframe(style_df(view_df), use_container_width=True, height=520)

    # ===== ì—‘ì…€ ë‚´ë³´ë‚´ê¸° =====
    st.divider()
    st.subheader("ğŸ“¥ ë°œì£¼ì„œ ë‚´ë³´ë‚´ê¸°")
    st.caption("ê°€ë…ì„± í–¥ìƒ ì„œì‹(ì—´ ë„ˆë¹„/í—¤ë” ìƒ‰/ì¡°ê±´ë¶€ì„œì‹/ê³ ì •/í•„í„°) ì ìš©. ê°€ê²©/ë‹¨ê°€ ì—´ ì—†ìŒ.")

    if export_mode == "ê·¸ë£¹ë³„ ê°œë³„ íŒŒì¼ (ZIP)":
        if st.button("ZIP ë§Œë“¤ê¸°"):
            zip_buffer = io.BytesIO()
            with zipfile.ZipFile(zip_buffer, "w") as zipf:
                for key, group in merged.groupby(group_by_option):
                    output = io.BytesIO()
                    with pd.ExcelWriter(output, engine="xlsxwriter") as writer:
                        sheet_df = group.copy()
                        sheet_df = sheet_df[[c for c in col_order if c in sheet_df.columns]]
                        sheet_name = "ë°œì£¼ì„œ"
                        write_formatted_sheet(writer, sheet_name, sheet_df)
                    safe_key = str(key).replace("/", "-")
                    filename = f"{safe_key} ë°œì£¼ì„œ(ìµœê·¼{selected_days}ì¼).xlsx"
                    zipf.writestr(filename, output.getvalue())
            zip_buffer.seek(0)
            st.download_button("ğŸ“¦ ZIP íŒŒì¼ ë‹¤ìš´ë¡œë“œ", data=zip_buffer, file_name=f"ë°œì£¼ì„œ_ì „ì²´_ìµœê·¼{selected_days}ì¼.zip", mime="application/zip")
    else:
        if st.button("ì—‘ì…€(í•œ íŒŒì¼, íƒ­ êµ¬ë¶„) ë§Œë“¤ê¸°"):
            xls_buffer = io.BytesIO()
            with pd.ExcelWriter(xls_buffer, engine="xlsxwriter") as writer:
                for key, group in merged.groupby(group_by_option):
                    sheet_df = group.copy()
                    sheet_df = sheet_df[[c for c in col_order if c in sheet_df.columns]]
                    sheet_name = sanitize_sheet_name(key)
                    write_formatted_sheet(writer, sheet_name, sheet_df)
            xls_buffer.seek(0)
            st.download_button("ğŸ“„ ì—‘ì…€ ë‹¤ìš´ë¡œë“œ", data=xls_buffer, file_name=f"ë°œì£¼ì„œ_íƒ­êµ¬ë¶„_ìµœê·¼{selected_days}ì¼.xlsx", mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet")
else:
    st.info("ğŸ“‚ ì‚¬ì´ë“œë°”ì—ì„œ **ë§¤ì¶œìë£Œ, ë§¤ì…ìë£Œ, í˜„ì¬ê³ ** íŒŒì¼ì„ ëª¨ë‘ ì—…ë¡œë“œí•˜ì„¸ìš”.")
