
import streamlit as st
import pandas as pd
import io
import zipfile
import os
import re
from datetime import timedelta

st.set_page_config(page_title="ì‹ ëª…ì•½í’ˆ ìë™ë°œì£¼(ì œì¡°ì‚¬ ê¸°ì¤€ ì „ìš©)", layout="wide")

# ============= ì‚¬ì´ë“œë°” / í—¤ë” =============
st.sidebar.header("ğŸ“‚ íŒŒì¼ ì—…ë¡œë“œ")
sales_file = st.sidebar.file_uploader("ë§¤ì¶œìë£Œ ì—…ë¡œë“œ", type=["xlsx"])
purchase_file = st.sidebar.file_uploader("ë§¤ì…ìë£Œ ì—…ë¡œë“œ", type=["xlsx"])
stock_file = st.sidebar.file_uploader("í˜„ì¬ê³  ì—…ë¡œë“œ", type=["xlsx"])
logo_upload = st.sidebar.file_uploader("ë¡œê³  ì´ë¯¸ì§€(ì„ íƒ)", type=["png","jpg","jpeg","webp"])
manu_map_file = st.sidebar.file_uploader("ì œì¡°ì‚¬ ë§¤í•‘í‘œ(ì„ íƒ: from,to)", type=["xlsx","csv"], help="ë°œê²¬ëœ ì œì¡°ì‚¬ëª…ì„ í‘œì¤€ëª…ìœ¼ë¡œ ì¹˜í™˜")

st.sidebar.divider()
mode = st.sidebar.radio("ğŸ“… ë¶„ì„ ê¸°ê°„", ["ìë™ (ìµœê·¼ 3ê°œì›”)", "ìˆ˜ë™ ì§€ì •"])

st.sidebar.divider()
use_recent_purchase = st.sidebar.checkbox("ìµœê·¼ ì…ê³ ìˆ˜ëŸ‰ ë°˜ì˜í•˜ì—¬ ê³¼ë°œì£¼ ë°©ì§€", value=True)
recent_days = st.sidebar.number_input("ìµœê·¼ ì…ê³  ë°˜ì˜ ì¼ìˆ˜", min_value=1, max_value=90, value=14, step=1)

st.sidebar.divider()
days_options = list(range(1, 366))
days_label_map = {d: f"{d}ì¼" for d in days_options}
selected_days = st.sidebar.selectbox("ë°œì£¼ ê¸°ì¤€(ìµœê·¼ Nì¼ íŒë§¤ëŸ‰)", options=days_options, format_func=lambda x: days_label_map[x], index=29)  # ê¸°ë³¸ 30ì¼

min_shortage = st.sidebar.number_input("ë¶€ì¡±ìˆ˜ëŸ‰ í•˜í•œ(ì´ìƒë§Œ í‘œì‹œ)", min_value=0, value=0, step=1)
show_only_to_order = st.sidebar.checkbox("ë°œì£¼ í•„ìš” í•­ëª©ë§Œ ë³´ê¸°(ë¶€ì¡±ìˆ˜ëŸ‰>0)", value=True)

st.sidebar.divider()
export_mode = st.sidebar.radio("ì—‘ì…€ ë‚´ë³´ë‚´ê¸° ë°©ì‹", ["ê·¸ë£¹ë³„ ê°œë³„ íŒŒì¼ (ZIP)", "í•œ íŒŒì¼(íƒ­ êµ¬ë¶„)"], index=1)

# ===== í—¤ë” ì˜ì—­ =====
c1, c2 = st.columns([1, 5])
with c1:
    try:
        if logo_upload is not None:
            st.image(logo_upload, width=100)
        elif os.path.exists("ë¡œê³ ë¦¬ë‰´ì–¼.png"):
            st.image("ë¡œê³ ë¦¬ë‰´ì–¼.png", width=230)
        else:
            st.empty()
    except Exception:
        st.empty()
with c2:
    st.title("ğŸ’Š ì‹ ëª…ì•½í’ˆ ìë™ë°œì£¼ì•±")
    

# ======== ìœ í‹¸ ========
PLACEHOLDER_SET = {"", "NONE", "NAN", "NULL", "-", "ë¯¸ì •", "ê¸°íƒ€", "ë¯¸ì§€ì •"}

def normalize_columns(df, mapping):
    df = df.copy()
    df.rename(columns={k: v for k, v in mapping.items() if k in df.columns}, inplace=True)
    return df

def require_columns(df, required, name):
    missing = [c for c in required if c not in df.columns]
    if missing:
        st.error(f"{name}ì— í•„ìš”í•œ ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤: {', '.join(missing)}")
        st.stop()

def to_upper_strip(series):
    return series.astype(str).str.strip().str.upper()

def clean_manu(series):
    s = series.astype(str).str.upper()
    # ë²•ì¸í‘œê¸°, íŠ¹ìˆ˜ê¸°í˜¸ ì œê±°
    for a,b in [("ãˆœ",""),("(ì£¼)",""),("ì£¼ì‹íšŒì‚¬",""),("(ìœ )",""),("ìœ í•œíšŒì‚¬",""),("(ì¬)",""),("ì¬ë‹¨ë²•ì¸",""),("(ì‚¬)",""),("ì‚¬ë‹¨ë²•ì¸","")]:
        s = s.str.replace(a, b, regex=False)
    s = s.str.replace(r"\s+", " ", regex=True).str.strip()
    s = s.replace(list(PLACEHOLDER_SET), pd.NA)
    return s

def apply_manu_mapping(series, mapping_df):
    if mapping_df is None:
        return series
    m = mapping_df.copy()
    m.columns = [c.strip().lower() for c in m.columns]
    if not set(["from","to"]).issubset(set(m.columns)):
        return series
    s_clean = series.astype(str).str.upper().str.strip()
    m["from"] = m["from"].astype(str).str.upper().str.strip()
    m["to"] = m["to"].astype(str).str.strip()
    return s_clean.map(dict(zip(m["from"], m["to"]))).where(lambda x: x.notna(), series)

def sanitize_sheet_name(name: str) -> str:
    if name is None or str(name).strip() == "":
        return "ë¯¸ì§€ì •"
    s = str(name)
    s = re.sub(r"[\[\]\*\?/\\:]", "-", s)
    return s[:31]

def write_formatted_sheet(writer, sheet_name, df):
    df = df.copy()
    df.to_excel(writer, index=False, sheet_name=sheet_name)
    workbook  = writer.book
    ws = writer.sheets[sheet_name]

    header_fmt = workbook.add_format({"bold": True, "bg_color": "#F2F4F7", "border": 1, "align": "center", "valign": "vcenter"})
    num_fmt    = workbook.add_format({"num_format": "#,##0"})
    strong_fmt = workbook.add_format({"bg_color": "#FFE5E5", "bold": True})
    over_fmt   = workbook.add_format({"bg_color": "#EAF4FF"})
    base_fmt   = workbook.add_format({"text_wrap": False})

    # í—¤ë” ì„œì‹
    for col_idx, col in enumerate(df.columns):
        ws.write(0, col_idx, col, header_fmt)

    # ì—´ ë„ˆë¹„ ìë™
    for i, col in enumerate(df.columns):
        try:
            maxlen = max(df[col].astype(str).map(len).max(), len(col))
        except Exception:
            maxlen = len(col)
        ws.set_column(i, i, min(maxlen + 2, 40), num_fmt if pd.api.types.is_numeric_dtype(df[col]) else base_fmt)

    ws.set_default_row(20)
    ws.set_row(0, 24)
    ws.freeze_panes(1, 0)
    ws.autofilter(0, 0, len(df), len(df.columns)-1)

    # ì¡°ê±´ë¶€ì„œì‹
    col_map = {c:i for i,c in enumerate(df.columns)}
    last_row = len(df)
    if "ë¶€ì¡±ìˆ˜ëŸ‰" in col_map:
        i = col_map["ë¶€ì¡±ìˆ˜ëŸ‰"]
        ws.conditional_format(1, i, last_row, i, {"type":"cell","criteria":">","value":0,"format":strong_fmt})
    if "ë°œì£¼ìˆ˜ëŸ‰" in col_map:
        i = col_map["ë°œì£¼ìˆ˜ëŸ‰"]
        ws.conditional_format(1, i, last_row, i, {"type":"cell","criteria":">","value":0,"format":strong_fmt})
    if "ê³¼ì¬ê³ " in col_map:
        i = col_map["ê³¼ì¬ê³ "]
        ws.conditional_format(1, i, last_row, i, {"type":"cell","criteria":">","value":0,"format":over_fmt})

def manu_mapping_template(sales_df, purchase_df, stock_df):
    names = []
    for df in [sales_df, purchase_df, stock_df]:
        if "ì œ ì¡° ì‚¬" in df.columns:
            vals = df["ì œ ì¡° ì‚¬"].dropna().astype(str).str.strip().unique().tolist()
            names.extend(vals)
    uniq = sorted(set([v for v in names if v and v.upper() not in PLACEHOLDER_SET]))
    tpl = pd.DataFrame({"from": uniq, "to": [""]*len(uniq)})
    csv = io.BytesIO(); tpl.to_csv(csv, index=False, encoding="utf-8-sig"); csv.seek(0)
    return csv, len(uniq)

# ======== ë©”ì¸ ë¡œì§ ========
if sales_file and purchase_file and stock_file:
    sales_df = pd.read_excel(sales_file)  # ë§¤ì¶œ
    purchase_df = pd.read_excel(purchase_file)  # ë§¤ì…(ì…ê³ )
    stock_df = pd.read_excel(stock_file)  # í˜„ì¬ê³ 

    # ì»¬ëŸ¼ ì •ê·œí™”(ë³„ì¹­ ëŒ€ì‘)
    sales_df = normalize_columns(sales_df, {
        "ê±°ë˜ì¼ì": "ëª…ì„¸ì¼ì", "ì¼ì": "ëª…ì„¸ì¼ì", "ë§¤ì¶œì²˜": "ë§¤ ì¶œ ì²˜",
        "ìƒí’ˆëª…": "ìƒ í’ˆ ëª…", "í¬ì¥ ë‹¨ìœ„": "í¬ì¥ë‹¨ìœ„", "ì œì¡°ì‚¬": "ì œ ì¡° ì‚¬", "ì œì•½ì‚¬": "ì œ ì¡° ì‚¬",
    })
    purchase_df = normalize_columns(purchase_df, {
        "ì…ê³ ì¼": "ì…ê³ ì¼ì", "ê±°ë˜ì²˜": "ë§¤ ì… ì²˜", "ë§¤ì…ì²˜": "ë§¤ ì… ì²˜", "ê³µê¸‰ì²˜": "ë§¤ ì… ì²˜",
        "ìƒí’ˆëª…": "ìƒ í’ˆ ëª…", "í¬ì¥ ë‹¨ìœ„": "í¬ì¥ë‹¨ìœ„", "ì œì¡°ì‚¬": "ì œ ì¡° ì‚¬", "ì œì•½ì‚¬": "ì œ ì¡° ì‚¬"
    })
    stock_df = normalize_columns(stock_df, {
        "ìƒí’ˆëª…": "ìƒ í’ˆ ëª…", "í¬ì¥ ë‹¨ìœ„": "í¬ì¥ë‹¨ìœ„", "ì œì¡°ì‚¬": "ì œ ì¡° ì‚¬", "ì œì•½ì‚¬": "ì œ ì¡° ì‚¬",
        "ì¬ê³ ": "ì¬ê³ ìˆ˜ëŸ‰"
    })

    # í•„ìˆ˜ ì»¬ëŸ¼ ì²´í¬
    require_columns(sales_df, ["ëª…ì„¸ì¼ì", "ìƒ í’ˆ ëª…", "í¬ì¥ë‹¨ìœ„", "ìˆ˜ëŸ‰"], "ë§¤ì¶œìë£Œ")
    require_columns(purchase_df, ["ì…ê³ ì¼ì", "ìƒ í’ˆ ëª…", "í¬ì¥ë‹¨ìœ„", "ìˆ˜ëŸ‰"], "ë§¤ì…ìë£Œ")
    require_columns(stock_df, ["ìƒ í’ˆ ëª…", "í¬ì¥ë‹¨ìœ„", "ì¬ê³ ìˆ˜ëŸ‰"], "í˜„ì¬ê³ ")

    # ë¬¸ìì—´ ì •ë¦¬
    for df in [sales_df, purchase_df, stock_df]:
        df["ìƒ í’ˆ ëª…"] = to_upper_strip(df["ìƒ í’ˆ ëª…"])
        df["í¬ì¥ë‹¨ìœ„"] = to_upper_strip(df["í¬ì¥ë‹¨ìœ„"])

    # ë‚ ì§œí˜•
    sales_df["ëª…ì„¸ì¼ì"] = pd.to_datetime(sales_df["ëª…ì„¸ì¼ì"], errors="coerce")
    purchase_df["ì…ê³ ì¼ì"] = pd.to_datetime(purchase_df["ì…ê³ ì¼ì"], errors="coerce")

    # ====== ì œì¡°ì‚¬ ì±„ìš°ê¸°/ë³´ì • ======
    for df in [sales_df, purchase_df, stock_df]:
        if "ì œ ì¡° ì‚¬" in df.columns:
            df["ì œ ì¡° ì‚¬"] = clean_manu(df["ì œ ì¡° ì‚¬"])
            # ë§¤í•‘í‘œ ì ìš©
            if manu_map_file is not None:
                try:
                    map_df = pd.read_excel(manu_map_file) if manu_map_file.name.lower().endswith(".xlsx") else pd.read_csv(manu_map_file)
                except Exception:
                    map_df = None
                if map_df is not None:
                    df["ì œ ì¡° ì‚¬"] = apply_manu_mapping(df["ì œ ì¡° ì‚¬"], map_df)

    # 1) í˜„ì¬ê³ ì— ì œì¡°ì‚¬ ì—†ë‹¤ë©´, ë§¤ì…ì˜ ìµœê·¼ ì´ë ¥ìœ¼ë¡œ ë³´ê°•
    purchase_sorted = purchase_df.sort_values("ì…ê³ ì¼ì")
    if "ì œ ì¡° ì‚¬" in purchase_df.columns:
        manu_last_by_key = purchase_sorted.groupby(["ìƒ í’ˆ ëª…","í¬ì¥ë‹¨ìœ„"])["ì œ ì¡° ì‚¬"].agg(lambda s: s.dropna().iloc[-1] if s.dropna().shape[0] else pd.NA).reset_index()
        stock_df = stock_df.merge(manu_last_by_key, on=["ìƒ í’ˆ ëª…","í¬ì¥ë‹¨ìœ„"], how="left", suffixes=("","_ìµœê·¼ì…ê³ "))
        if "ì œ ì¡° ì‚¬" in stock_df.columns and "ì œ ì¡° ì‚¬_ìµœê·¼ì…ê³ " in stock_df.columns:
            stock_df["ì œ ì¡° ì‚¬"] = stock_df["ì œ ì¡° ì‚¬"].fillna(stock_df["ì œ ì¡° ì‚¬_ìµœê·¼ì…ê³ "])
            stock_df.drop(columns=["ì œ ì¡° ì‚¬_ìµœê·¼ì…ê³ "], inplace=True)
        # 2) í¬ì¥ë‹¨ìœ„ê°€ ë‹¬ë¼ë„ ìƒí’ˆëª… ê¸°ì¤€ìœ¼ë¡œ ë³´ê°•
        manu_last_by_name = purchase_sorted.groupby(["ìƒ í’ˆ ëª…"])["ì œ ì¡° ì‚¬"].agg(lambda s: s.dropna().iloc[-1] if s.dropna().shape[0] else pd.NA).reset_index()
        stock_df = stock_df.merge(manu_last_by_name, on=["ìƒ í’ˆ ëª…"], how="left", suffixes=("","_ì´ë¦„ê¸°ì¤€"))
        if "ì œ ì¡° ì‚¬" in stock_df.columns and "ì œ ì¡° ì‚¬_ì´ë¦„ê¸°ì¤€" in stock_df.columns:
            stock_df["ì œ ì¡° ì‚¬"] = stock_df["ì œ ì¡° ì‚¬"].fillna(stock_df["ì œ ì¡° ì‚¬_ì´ë¦„ê¸°ì¤€"])
            stock_df.drop(columns=["ì œ ì¡° ì‚¬_ì´ë¦„ê¸°ì¤€"], inplace=True)

    # ===== ë°œì£¼ ê¸°ì¤€: ìµœê·¼ Nì¼ íŒë§¤ëŸ‰(ì´í•©) =====
    max_sale_date = sales_df["ëª…ì„¸ì¼ì"].max()
    nday_start = max_sale_date - pd.Timedelta(days=int(selected_days))
    nday_sales = sales_df[(sales_df["ëª…ì„¸ì¼ì"] > nday_start) & (sales_df["ëª…ì„¸ì¼ì"] <= max_sale_date)]
    nday_qty = nday_sales.groupby(["ìƒ í’ˆ ëª…", "í¬ì¥ë‹¨ìœ„"], as_index=False)["ìˆ˜ëŸ‰"].sum()
    nday_qty.rename(columns={"ìˆ˜ëŸ‰": f"ìµœê·¼{selected_days}ì¼_íŒë§¤ëŸ‰"}, inplace=True)
    nday_qty["ê¸°ì¤€íŒë§¤ëŸ‰"] = nday_qty[f"ìµœê·¼{selected_days}ì¼_íŒë§¤ëŸ‰"].astype(int)

    # í˜„ì¬ê³  ë³‘í•©(ì œì¡°ì‚¬ í¬í•¨)
    cols_to_pull = ["ìƒ í’ˆ ëª…", "í¬ì¥ë‹¨ìœ„", "ì¬ê³ ìˆ˜ëŸ‰"]
    if "ì œ ì¡° ì‚¬" in stock_df.columns: cols_to_pull.append("ì œ ì¡° ì‚¬")
    merged = nday_qty.merge(stock_df[cols_to_pull].drop_duplicates(), on=["ìƒ í’ˆ ëª…", "í¬ì¥ë‹¨ìœ„"], how="left")

    # ìµœê·¼ ì…ê³  ë°˜ì˜(ì˜µì…˜)
    if use_recent_purchase:
        cutoff = purchase_df["ì…ê³ ì¼ì"].max() - pd.Timedelta(days=int(recent_days))
        recent_purchase = purchase_df[purchase_df["ì…ê³ ì¼ì"] >= cutoff]
        recent_in_qty = recent_purchase.groupby(["ìƒ í’ˆ ëª…", "í¬ì¥ë‹¨ìœ„"], as_index=False)["ìˆ˜ëŸ‰"].sum()
        recent_in_qty.rename(columns={"ìˆ˜ëŸ‰": "ìµœê·¼ì…ê³ ìˆ˜ëŸ‰"}, inplace=True)
        merged = merged.merge(recent_in_qty, on=["ìƒ í’ˆ ëª…", "í¬ì¥ë‹¨ìœ„"], how="left")
        merged["ìµœê·¼ì…ê³ ìˆ˜ëŸ‰"] = merged["ìµœê·¼ì…ê³ ìˆ˜ëŸ‰"].fillna(0).astype(int)
    else:
        merged["ìµœê·¼ì…ê³ ìˆ˜ëŸ‰"] = 0

    # ë¶€ì¡±/ê³¼ì¬ê³ /ë°œì£¼ìˆ˜ëŸ‰ ê³„ì‚°
    merged["ì¬ê³ ìˆ˜ëŸ‰"] = merged["ì¬ê³ ìˆ˜ëŸ‰"].fillna(0).astype(int)
    merged["ê¸°ì¤€íŒë§¤ëŸ‰"] = merged["ê¸°ì¤€íŒë§¤ëŸ‰"].fillna(0).astype(int)

    merged["ë¶€ì¡±ìˆ˜ëŸ‰"] = (merged["ê¸°ì¤€íŒë§¤ëŸ‰"] - merged["ì¬ê³ ìˆ˜ëŸ‰"] - merged["ìµœê·¼ì…ê³ ìˆ˜ëŸ‰"]).astype(int)
    merged["ë¶€ì¡±ìˆ˜ëŸ‰"] = merged["ë¶€ì¡±ìˆ˜ëŸ‰"].apply(lambda x: x if x > 0 else 0)

    merged["ê³¼ì¬ê³ "] = (merged["ì¬ê³ ìˆ˜ëŸ‰"] - merged["ê¸°ì¤€íŒë§¤ëŸ‰"]).astype(int)
    merged["ê³¼ì¬ê³ "] = merged["ê³¼ì¬ê³ "].apply(lambda x: x if x > 0 else 0)

    merged["ë°œì£¼ìˆ˜ëŸ‰"] = merged["ë¶€ì¡±ìˆ˜ëŸ‰"]

    # ì œì¡°ì‚¬ ìµœì¢… ì±„ì›€: None/ë¹ˆê°’ì„ 'ë¯¸ì§€ì •'ìœ¼ë¡œ
    if "ì œ ì¡° ì‚¬" in merged.columns:
        merged["ì œ ì¡° ì‚¬"] = merged["ì œ ì¡° ì‚¬"].where(merged["ì œ ì¡° ì‚¬"].notna() & ~merged["ì œ ì¡° ì‚¬"].isin(PLACEHOLDER_SET), "ë¯¸ì§€ì •")

    # ë³´ê¸° ì˜µì…˜ í•„í„°
    if min_shortage > 0:
        merged = merged[merged["ë¶€ì¡±ìˆ˜ëŸ‰"] >= int(min_shortage)]
    if show_only_to_order:
        merged = merged[merged["ë°œì£¼ìˆ˜ëŸ‰"] > 0]

    # ===== ìƒë‹¨ KPI =====
    k1, k2, k3, k4 = st.columns(4)
    k1.metric("ì´ í’ˆëª©ìˆ˜", f"{len(merged):,}")
    k2.metric("ë°œì£¼ í•„ìš” í’ˆëª©ìˆ˜", f"{(merged['ë°œì£¼ìˆ˜ëŸ‰'] > 0).sum():,}")
    k3.metric("ë¶€ì¡±ìˆ˜ëŸ‰ í•©ê³„", f"{int(merged['ë¶€ì¡±ìˆ˜ëŸ‰'].sum()):,}")
    k4.metric("ê³¼ì¬ê³  í•©ê³„", f"{int(merged['ê³¼ì¬ê³ '].sum()):,}")

    # ===== í•„í„° =====
    f1, f2 = st.columns([2, 1])
    with f1:
        keyword = st.text_input("ğŸ” ìƒí’ˆëª… ê²€ìƒ‰(ëŒ€ì†Œë¬¸ì ë¬´ì‹œ)", value="").strip().upper()
    with f2:
        manu_sel = st.multiselect("ì œì¡°ì‚¬ í•„í„°", sorted(pd.Series(merged.get("ì œ ì¡° ì‚¬", pd.Series())).dropna().unique().tolist())) if "ì œ ì¡° ì‚¬" in merged.columns else st.multiselect("ì œì¡°ì‚¬ í•„í„°", [])

    view_df = merged.copy()
    if keyword:
        view_df = view_df[view_df["ìƒ í’ˆ ëª…"].str.contains(keyword, na=False)]
    if manu_sel and "ì œ ì¡° ì‚¬" in view_df.columns:
        view_df = view_df[view_df["ì œ ì¡° ì‚¬"].isin(manu_sel)]

    # ===== í‘œì‹œ/ì •ë ¬ =====
    base_cols = ["ì œ ì¡° ì‚¬", "ìƒ í’ˆ ëª…", "í¬ì¥ë‹¨ìœ„",
                 "ì¬ê³ ìˆ˜ëŸ‰", f"ìµœê·¼{selected_days}ì¼_íŒë§¤ëŸ‰", "ê¸°ì¤€íŒë§¤ëŸ‰",
                 "ìµœê·¼ì…ê³ ìˆ˜ëŸ‰", "ë¶€ì¡±ìˆ˜ëŸ‰", "ê³¼ì¬ê³ ", "ë°œì£¼ìˆ˜ëŸ‰"]
    col_order = [c for c in base_cols if c in view_df.columns]
    view_df = view_df.drop_duplicates(subset=["ìƒ í’ˆ ëª…", "í¬ì¥ë‹¨ìœ„"]).copy()
    view_df = view_df[col_order].sort_values(["ì œ ì¡° ì‚¬", "ìƒ í’ˆ ëª…"]) if "ì œ ì¡° ì‚¬" in col_order else view_df[col_order]

    # ===== í‘œ ìŠ¤íƒ€ì¼ =====
    def style_df(df):
        def hi_short(v):
            try:
                v = int(v); return "background-color: #ffe5e5; font-weight: 700;" if v > 0 else ""
            except: return ""
        def hi_over(v):
            try:
                v = int(v); return "background-color: #eaf4ff;" if v > 0 else ""
            except: return ""
        num_cols = [c for c in [f"ìµœê·¼{selected_days}ì¼_íŒë§¤ëŸ‰","ì¬ê³ ìˆ˜ëŸ‰","ê¸°ì¤€íŒë§¤ëŸ‰","ìµœê·¼ì…ê³ ìˆ˜ëŸ‰","ë¶€ì¡±ìˆ˜ëŸ‰","ê³¼ì¬ê³ ","ë°œì£¼ìˆ˜ëŸ‰"] if c in df.columns]
        styler = df.style.format("{:,}", subset=num_cols)
        if "ë¶€ì¡±ìˆ˜ëŸ‰" in df.columns:
            styler = styler.applymap(hi_short, subset=["ë¶€ì¡±ìˆ˜ëŸ‰","ë°œì£¼ìˆ˜ëŸ‰"] if "ë°œì£¼ìˆ˜ëŸ‰" in df.columns else ["ë¶€ì¡±ìˆ˜ëŸ‰"])
        if "ê³¼ì¬ê³ " in df.columns:
            styler = styler.applymap(hi_over, subset=["ê³¼ì¬ê³ "])
        return styler

    st.subheader("ğŸ“Š ë°œì£¼ ëŒ€ìƒ ë¯¸ë¦¬ë³´ê¸°")
    st.dataframe(style_df(view_df), use_container_width=True, height=520)

    # ===== ì œì¡°ì‚¬ ë¶„ì„ & í…œí”Œë¦¿ =====
    with st.expander("ğŸ·ï¸ ì œì¡°ì‚¬ ë¶„ì„/í…œí”Œë¦¿", expanded=False):
        if "ì œ ì¡° ì‚¬" in merged.columns:
            unknown = merged[merged["ì œ ì¡° ì‚¬"].isin(["ë¯¸ì§€ì •"])]
            c1, c2 = st.columns(2)
            with c1:
                st.metric("ì œì¡°ì‚¬ ë¯¸ì§€ì • í’ˆëª©ìˆ˜", f"{len(unknown):,}")
                st.dataframe(unknown[["ìƒ í’ˆ ëª…","í¬ì¥ë‹¨ìœ„",f"ìµœê·¼{selected_days}ì¼_íŒë§¤ëŸ‰","ì¬ê³ ìˆ˜ëŸ‰","ë°œì£¼ìˆ˜ëŸ‰"]].head(200), use_container_width=True)
            with c2:
                tpl_csv, n_names = manu_mapping_template(sales_df, purchase_df, stock_df)
                st.caption(f"ë°œê²¬ëœ ì œì¡°ì‚¬ ì›ë³¸ëª… ê°œìˆ˜: {n_names:,}ê°œ")
                st.download_button("ğŸ§© ì œì¡°ì‚¬ ë§¤í•‘í‘œ í…œí”Œë¦¿(CSV)", data=tpl_csv, file_name="manufacturer_mapping_template.csv", mime="text/csv")
                st.write("í…œí”Œë¦¿ì˜ **from â†’ to**ì— í‘œì¤€ ì œì¡°ì‚¬ëª…ì„ ì…ë ¥ í›„, ì¢Œì¸¡ ì—…ë¡œë”ì— ì˜¬ë ¤ì£¼ì‹œë©´ ë°˜ì˜ë©ë‹ˆë‹¤.")

    # ===== ì—‘ì…€ ë‚´ë³´ë‚´ê¸° =====
    st.divider()
    st.subheader("ğŸ“¥ ë°œì£¼ì„œ ë‚´ë³´ë‚´ê¸° (ì œì¡°ì‚¬ ê¸°ì¤€)")
  

    export_df = merged.copy()
    export_cols = [c for c in base_cols if c in export_df.columns]  # ë§¤ì…ì²˜ ì—†ìŒ
    export_df = export_df[export_cols]

    if export_mode == "ê·¸ë£¹ë³„ ê°œë³„ íŒŒì¼ (ZIP)":
        if st.button("ZIP ë§Œë“¤ê¸°"):
            zip_buffer = io.BytesIO()
            with zipfile.ZipFile(zip_buffer, "w") as zipf:
                for manu, group in export_df.groupby(["ì œ ì¡° ì‚¬"], dropna=False):
                    title = str(manu) if manu else "ë¯¸ì§€ì •"
                    output = io.BytesIO()
                    with pd.ExcelWriter(output, engine="xlsxwriter") as writer:
                        sheet_df = group.copy()
                        write_formatted_sheet(writer, "ë°œì£¼ì„œ", sheet_df)
                    filename = f"{title.replace('/', '-')} ë°œì£¼ì„œ(ìµœê·¼{selected_days}ì¼).xlsx"
                    zipf.writestr(filename, output.getvalue())
            zip_buffer.seek(0)
            st.download_button("ğŸ“¦ ZIP íŒŒì¼ ë‹¤ìš´ë¡œë“œ", data=zip_buffer, file_name=f"ë°œì£¼ì„œ_ì „ì²´_ìµœê·¼{selected_days}ì¼.zip", mime="application/zip")
    else:
        if st.button("ì—‘ì…€(í•œ íŒŒì¼, íƒ­ êµ¬ë¶„) ë§Œë“¤ê¸°"):
            xls_buffer = io.BytesIO()
            with pd.ExcelWriter(xls_buffer, engine="xlsxwriter") as writer:
                for manu, group in export_df.groupby(["ì œ ì¡° ì‚¬"], dropna=False):
                    sheet_name = sanitize_sheet_name(manu if manu else "ë¯¸ì§€ì •")
                    write_formatted_sheet(writer, sheet_name, group.copy())
            xls_buffer.seek(0)
            st.download_button("ğŸ“„ ì—‘ì…€ ë‹¤ìš´ë¡œë“œ", data=xls_buffer, file_name=f"ë°œì£¼ì„œ_íƒ­êµ¬ë¶„_ìµœê·¼{selected_days}ì¼.xlsx", mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet")
else:
    st.info(
        "ğŸ“‚ **ì¢Œì¸¡ ì‚¬ì´ë“œë°”**ì—ì„œ **ë§¤ì¶œ ìë£Œ, ë§¤ì… ìë£Œ, í˜„ì¬ê³ ** íŒŒì¼ì„ ëª¨ë‘ ì—…ë¡œë“œí•˜ì„¸ìš”.\n\n"
       
    )
